{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu --no-cache-dir\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ8Vp-kScSyE",
        "outputId": "7a40d6ce-9964-4b14-e30f-31cd6da9091b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.9.0.post1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVAFzYPU8N2l",
        "outputId": "7ecd361d-63b7-4aa4-b95b-9bb0ecba14b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: farm-haystack[all] in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: boilerpy3 in /usr/local/lib/python3.11/dist-packages (from farm-haystack[all]) (1.0.7)\n",
            "Requirement already satisfied: events in /usr/local/lib/python3.11/dist-packages (from farm-haystack[all]) (0.5)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from farm-haystack[all]) (0.28.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from farm-haystack[all]) (4.23.0)\n",
            "Requirement already satisfied: lazy-imports==0.3.1 in /usr/local/lib/python3.11/dist-packages (from farm-haystack[all]) (0.3.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from farm-haystack[all]) (10.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from farm-haystack[all]) (3.4.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from farm-haystack[all]) (9.0.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from farm-haystack[all]) (4.3.6)\n",
            "Requirement already satisfied: posthog in /usr/local/lib/python3.11/dist-packages (from farm-haystack[all]) (3.9.3)\n",
            "Requirement already satisfied: prompthub-py==4.0.0 in /usr/local/lib/python3.11/dist-packages (from farm-haystack[all]) (4.0.0)\n",
            "Requirement already satisfied: pydantic<2 in /usr/local/lib/python3.11/dist-packages (from farm-haystack[all]) (1.10.21)\n",
            "Requirement already satisfied: quantulum3 in /usr/local/lib/python3.11/dist-packages (from farm-haystack[all]) (0.9.2)\n",
            "Requirement already satisfied: rank-bm25 in /usr/local/lib/python3.11/dist-packages (from farm-haystack[all]) (0.2.2)\n",
            "Requirement already satisfied: requests-cache<1.0.0 in /usr/local/lib/python3.11/dist-packages (from farm-haystack[all]) (0.9.8)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from farm-haystack[all]) (1.6.0)\n",
            "Requirement already satisfied: sseclient-py in /usr/local/lib/python3.11/dist-packages (from farm-haystack[all]) (1.8.0)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.11/dist-packages (from farm-haystack[all]) (9.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from farm-haystack[all]) (0.8.0)\n",
            "Requirement already satisfied: transformers<5.0,>=4.46 in /usr/local/lib/python3.11/dist-packages (from farm-haystack[all]) (4.47.1)\n",
            "Collecting azure-ai-formrecognizer>=3.2.0b2 (from farm-haystack[all])\n",
            "  Using cached azure_ai_formrecognizer-3.3.3-py3-none-any.whl.metadata (64 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from farm-haystack[all]) (4.12.3)\n",
            "Collecting boto3>=1.28.57 (from farm-haystack[all])\n",
            "  Using cached boto3-1.36.5-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting elastic-transport<8 (from farm-haystack[all])\n",
            "  Using cached elastic_transport-7.16.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting elasticsearch<8,>=7.17 (from farm-haystack[all])\n",
            "  Using cached elasticsearch-7.17.12-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting faiss-cpu<=1.7.2,>=1.6.3 (from farm-haystack[all])\n",
            "  Using cached faiss-cpu-1.7.2.tar.gz (42 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting langdetect (from farm-haystack[all])\n",
            "  Using cached langdetect-1.0.9-py3-none-any.whl\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from farm-haystack[all]) (3.7)\n",
            "Collecting mlflow (from farm-haystack[all])\n",
            "  Using cached mlflow-2.20.0-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: nltk>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from farm-haystack[all]) (3.9.1)\n",
            "Collecting openai-whisper>=20231106 (from farm-haystack[all])\n",
            "  Using cached openai_whisper-20240930-py3-none-any.whl\n",
            "Collecting opensearch-py>=2 (from farm-haystack[all])\n",
            "  Using cached opensearch_py-2.8.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pdf2image>1.14 (from farm-haystack[all])\n",
            "  Using cached pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting pinecone-client<3,>=2.0.11 (from farm-haystack[all])\n",
            "  Using cached pinecone_client-2.2.4-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting psycopg2-binary (from farm-haystack[all])\n",
            "  Using cached psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting pymongo>=4.6 (from farm-haystack[all])\n",
            "  Using cached pymongo-4.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting pytesseract>0.3.7 (from farm-haystack[all])\n",
            "  Using cached pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting python-docx (from farm-haystack[all])\n",
            "  Using cached python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting python-frontmatter (from farm-haystack[all])\n",
            "  Using cached python_frontmatter-1.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting python-magic (from farm-haystack[all])\n",
            "  Using cached python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting python-pptx<=1.0 (from farm-haystack[all])\n",
            "  Using cached python_pptx-1.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting rapidfuzz<2.8.0,>=2.0.15 (from farm-haystack[all])\n",
            "  Using cached rapidfuzz-2.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from farm-haystack[all]) (1.13.1)\n",
            "Collecting selenium>=4.11.0 (from farm-haystack[all])\n",
            "  Using cached selenium-4.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: sentence-transformers<=3.0.0,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from farm-haystack[all]) (3.0.0)\n",
            "Collecting seqeval (from farm-haystack[all])\n",
            "  Using cached seqeval-1.2.2-py3-none-any.whl\n",
            "Collecting sqlalchemy-utils (from farm-haystack[all])\n",
            "  Using cached SQLAlchemy_Utils-0.41.2-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting sqlalchemy<2,>=1.4.2 (from farm-haystack[all])\n",
            "  Using cached SQLAlchemy-1.4.54-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting tika (from farm-haystack[all])\n",
            "  Using cached tika-2.6.0-py3-none-any.whl\n",
            "Collecting weaviate-client>2 (from farm-haystack[all])\n",
            "  Using cached weaviate_client-4.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting azure-core>=1.23.0 (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack[all])\n",
            "  Using cached azure_core-1.32.0-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting msrest>=0.6.21 (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack[all])\n",
            "  Using cached msrest-0.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting azure-common>=1.1 (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack[all])\n",
            "  Using cached azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack[all]) (4.12.2)\n",
            "Collecting botocore<1.37.0,>=1.36.5 (from boto3>=1.28.57->farm-haystack[all])\n",
            "  Using cached botocore-1.36.5-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.28.57->farm-haystack[all])\n",
            "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3>=1.28.57->farm-haystack[all])\n",
            "  Using cached s3transfer-0.11.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting urllib3<2,>=1.21.1 (from elastic-transport<8->farm-haystack[all])\n",
            "  Using cached urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "Requirement already satisfied: six>=1.12 in /usr/local/lib/python3.11/dist-packages (from elastic-transport<8->farm-haystack[all]) (1.17.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from elastic-transport<8->farm-haystack[all]) (2024.12.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9.1->farm-haystack[all]) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9.1->farm-haystack[all]) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9.1->farm-haystack[all]) (2024.11.6)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper>=20231106->farm-haystack[all]) (0.60.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper>=20231106->farm-haystack[all]) (2.5.1+cu121)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper>=20231106->farm-haystack[all]) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from opensearch-py>=2->farm-haystack[all]) (2.8.2)\n",
            "Collecting loguru>=0.5.0 (from pinecone-client<3,>=2.0.11->farm-haystack[all])\n",
            "  Using cached loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting dnspython>=2.0.0 (from pinecone-client<3,>=2.0.11->farm-haystack[all])\n",
            "  Using cached dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx<=1.0->farm-haystack[all])\n",
            "  Using cached XlsxWriter-3.2.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx<=1.0->farm-haystack[all]) (5.3.0)\n",
            "Collecting jarowinkler<2.0.0,>=1.2.0 (from rapidfuzz<2.8.0,>=2.0.15->farm-haystack[all])\n",
            "  Using cached jarowinkler-1.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.11/dist-packages (from requests-cache<1.0.0->farm-haystack[all]) (1.4.4)\n",
            "Requirement already satisfied: cattrs>=22.2 in /usr/local/lib/python3.11/dist-packages (from requests-cache<1.0.0->farm-haystack[all]) (24.1.2)\n",
            "Requirement already satisfied: url-normalize>=1.4 in /usr/local/lib/python3.11/dist-packages (from requests-cache<1.0.0->farm-haystack[all]) (1.4.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->farm-haystack[all]) (3.5.0)\n",
            "Collecting trio~=0.17 (from selenium>=4.11.0->farm-haystack[all])\n",
            "  Using cached trio-0.28.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium>=4.11.0->farm-haystack[all])\n",
            "  Using cached trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium>=4.11.0->farm-haystack[all]) (1.8.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<2,>=1.4.2->farm-haystack[all]) (3.1.1)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0,>=4.46->farm-haystack[all]) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0,>=4.46->farm-haystack[all]) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece,torch]<5.0,>=4.46; extra == \"all\"->farm-haystack[all]) (0.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece,torch]<5.0,>=4.46; extra == \"all\"->farm-haystack[all]) (4.25.5)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece,torch]<5.0,>=4.46; extra == \"all\"->farm-haystack[all]) (1.2.1)\n",
            "Collecting validators==0.34.0 (from weaviate-client>2->farm-haystack[all])\n",
            "  Using cached validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting authlib<1.3.2,>=1.2.1 (from weaviate-client>2->farm-haystack[all])\n",
            "  Using cached Authlib-1.3.1-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: pip is looking at multiple versions of weaviate-client to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting weaviate-client>2 (from farm-haystack[all])\n",
            "  Using cached weaviate_client-4.10.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Using cached weaviate_client-4.10.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Using cached weaviate_client-4.10.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Using cached weaviate_client-4.10.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting httpx (from farm-haystack[all])\n",
            "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting weaviate-client>2 (from farm-haystack[all])\n",
            "  Using cached weaviate_client-4.9.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Using cached weaviate_client-4.9.5-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Using cached weaviate_client-4.9.4-py3-none-any.whl.metadata (3.6 kB)\n",
            "INFO: pip is still looking at multiple versions of weaviate-client to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached weaviate_client-4.9.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Using cached weaviate_client-4.9.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Using cached weaviate_client-4.9.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Using cached weaviate_client-4.9.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Using cached weaviate_client-4.8.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Using cached weaviate_client-4.8.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting validators==0.33.0 (from weaviate-client>2->farm-haystack[all])\n",
            "  Using cached validators-0.33.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting authlib<2.0.0,>=1.2.1 (from weaviate-client>2->farm-haystack[all])\n",
            "  Using cached Authlib-1.4.0-py2.py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting weaviate-client>2 (from farm-haystack[all])\n",
            "  Using cached weaviate_client-4.7.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Using cached weaviate_client-4.7.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Using cached weaviate_client-4.6.7-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Using cached weaviate_client-4.6.5-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting validators==0.28.3 (from weaviate-client>2->farm-haystack[all])\n",
            "  Using cached validators-0.28.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting weaviate-client>2 (from farm-haystack[all])\n",
            "  Using cached weaviate_client-4.6.4-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Using cached weaviate_client-4.6.3-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting validators==0.28.1 (from weaviate-client>2->farm-haystack[all])\n",
            "  Using cached validators-0.28.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting weaviate-client>2 (from farm-haystack[all])\n",
            "  Using cached weaviate_client-4.6.2-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Using cached weaviate_client-4.6.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Using cached weaviate_client-4.6.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Using cached weaviate_client-4.5.7-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Using cached weaviate_client-4.5.6-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting validators==0.28.0 (from weaviate-client>2->farm-haystack[all])\n",
            "  Using cached validators-0.28.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting weaviate-client>2 (from farm-haystack[all])\n",
            "  Using cached weaviate_client-4.5.5-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting validators==0.22.0 (from weaviate-client>2->farm-haystack[all])\n",
            "  Using cached validators-0.22.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting weaviate-client>2 (from farm-haystack[all])\n",
            "  Using cached weaviate_client-4.5.4-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Using cached weaviate_client-4.5.3-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Using cached weaviate_client-4.5.2-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Using cached weaviate_client-4.5.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Using cached weaviate_client-4.5.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Using cached weaviate_client-4.4.4-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httpx (from farm-haystack[all])\n",
            "  Using cached httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting weaviate-client>2 (from farm-haystack[all])\n",
            "  Using cached weaviate_client-4.4.3-py3-none-any.whl.metadata (3.5 kB)\n",
            "  Using cached weaviate_client-4.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "  Using cached weaviate_client-4.4.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "  Using cached weaviate_client-4.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "  Using cached weaviate_client-3.26.7-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->farm-haystack[all]) (2.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->farm-haystack[all]) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->farm-haystack[all]) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->farm-haystack[all]) (0.14.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->farm-haystack[all]) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->farm-haystack[all]) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->farm-haystack[all]) (0.22.3)\n",
            "Collecting mlflow-skinny==2.20.0 (from mlflow->farm-haystack[all])\n",
            "  Using cached mlflow_skinny-2.20.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow->farm-haystack[all]) (3.1.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow->farm-haystack[all]) (3.1.5)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow->farm-haystack[all])\n",
            "  Using cached alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow->farm-haystack[all])\n",
            "  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow->farm-haystack[all])\n",
            "  Using cached graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow->farm-haystack[all])\n",
            "  Using cached gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow->farm-haystack[all]) (3.10.0)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.0->mlflow->farm-haystack[all]) (5.5.0)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.0->mlflow->farm-haystack[all]) (3.1.0)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.20.0->mlflow->farm-haystack[all])\n",
            "  Using cached databricks_sdk-0.41.0-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.0->mlflow->farm-haystack[all]) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.0->mlflow->farm-haystack[all]) (8.5.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.0->mlflow->farm-haystack[all]) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.0->mlflow->farm-haystack[all]) (1.29.0)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.0->mlflow->farm-haystack[all]) (0.5.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog->farm-haystack[all]) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog->farm-haystack[all]) (2.2.1)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.11/dist-packages (from quantulum3->farm-haystack[all]) (7.5.0)\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.11/dist-packages (from quantulum3->farm-haystack[all]) (0.5.14)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tika->farm-haystack[all]) (75.1.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->transformers[sentencepiece,torch]<5.0,>=4.46; extra == \"all\"->farm-haystack[all]) (5.9.5)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow->farm-haystack[all])\n",
            "  Using cached Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from authlib<2.0.0,>=1.2.1->weaviate-client>2->farm-haystack[all]) (43.0.3)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow->farm-haystack[all]) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow->farm-haystack[all]) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow->farm-haystack[all]) (1.9.0)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow->farm-haystack[all])\n",
            "  Using cached graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow->farm-haystack[all])\n",
            "  Using cached graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4,>=2.11->mlflow->farm-haystack[all]) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow->farm-haystack[all]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow->farm-haystack[all]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow->farm-haystack[all]) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow->farm-haystack[all]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow->farm-haystack[all]) (3.2.1)\n",
            "Collecting isodate>=0.6.0 (from msrest>=0.6.21->azure-ai-formrecognizer>=3.2.0b2->farm-haystack[all])\n",
            "  Using cached isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from msrest>=0.6.21->azure-ai-formrecognizer>=3.2.0b2->farm-haystack[all]) (1.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper>=20231106->farm-haystack[all]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper>=20231106->farm-haystack[all]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper>=20231106->farm-haystack[all]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper>=20231106->farm-haystack[all]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper>=20231106->farm-haystack[all]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper>=20231106->farm-haystack[all]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper>=20231106->farm-haystack[all]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper>=20231106->farm-haystack[all]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper>=20231106->farm-haystack[all]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper>=20231106->farm-haystack[all]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper>=20231106->farm-haystack[all]) (12.1.105)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper>=20231106->farm-haystack[all]) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper>=20231106->farm-haystack[all]) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper>=20231106->farm-haystack[all]) (1.3.0)\n",
            "Collecting sortedcontainers (from trio~=0.17->selenium>=4.11.0->farm-haystack[all])\n",
            "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting outcome (from trio~=0.17->selenium>=4.11.0->farm-haystack[all])\n",
            "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium>=4.11.0->farm-haystack[all]) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium>=4.11.0->farm-haystack[all])\n",
            "  Using cached wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium>=4.11.0->farm-haystack[all]) (1.7.1)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from inflect->quantulum3->farm-haystack[all]) (4.4.1)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from num2words->quantulum3->farm-haystack[all]) (0.6.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper>=20231106->farm-haystack[all]) (0.43.0)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.0->mlflow->farm-haystack[all]) (2.27.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.20.0->mlflow->farm-haystack[all]) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.20.0->mlflow->farm-haystack[all]) (3.21.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.0->mlflow->farm-haystack[all]) (1.2.15)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.20.0->mlflow->farm-haystack[all]) (0.50b0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-formrecognizer>=3.2.0b2->farm-haystack[all]) (3.2.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography->authlib<2.0.0,>=1.2.1->weaviate-client>2->farm-haystack[all]) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography->authlib<2.0.0,>=1.2.1->weaviate-client>2->farm-haystack[all]) (2.22)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.0->mlflow->farm-haystack[all]) (1.17.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.20.0->mlflow->farm-haystack[all]) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.0->mlflow->farm-haystack[all]) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.0->mlflow->farm-haystack[all]) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.0->mlflow->farm-haystack[all]) (0.6.1)\n",
            "Using cached azure_ai_formrecognizer-3.3.3-py3-none-any.whl (301 kB)\n",
            "Using cached boto3-1.36.5-py3-none-any.whl (139 kB)\n",
            "Using cached elastic_transport-7.16.0-py2.py3-none-any.whl (35 kB)\n",
            "Using cached elasticsearch-7.17.12-py2.py3-none-any.whl (385 kB)\n",
            "Using cached opensearch_py-2.8.0-py3-none-any.whl (353 kB)\n",
            "Using cached pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Using cached pinecone_client-2.2.4-py3-none-any.whl (179 kB)\n",
            "Using cached pymongo-4.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "Using cached pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Using cached python_pptx-1.0.0-py3-none-any.whl (472 kB)\n",
            "Using cached rapidfuzz-2.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "Using cached selenium-4.28.1-py3-none-any.whl (9.5 MB)\n",
            "Using cached SQLAlchemy-1.4.54-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "Using cached weaviate_client-3.26.7-py3-none-any.whl (120 kB)\n",
            "Using cached mlflow-2.20.0-py3-none-any.whl (28.3 MB)\n",
            "Using cached mlflow_skinny-2.20.0-py3-none-any.whl (6.0 MB)\n",
            "Using cached psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Using cached python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "Using cached python_frontmatter-1.1.0-py3-none-any.whl (9.8 kB)\n",
            "Using cached python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Using cached SQLAlchemy_Utils-0.41.2-py3-none-any.whl (93 kB)\n",
            "Using cached alembic-1.14.1-py3-none-any.whl (233 kB)\n",
            "Using cached Authlib-1.4.0-py2.py3-none-any.whl (225 kB)\n",
            "Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
            "Using cached azure_core-1.32.0-py3-none-any.whl (198 kB)\n",
            "Using cached botocore-1.36.5-py3-none-any.whl (13.3 MB)\n",
            "Using cached dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "Using cached docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "Using cached graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "Using cached gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "Using cached jarowinkler-1.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (115 kB)\n",
            "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Using cached loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "Using cached msrest-0.7.1-py3-none-any.whl (85 kB)\n",
            "Using cached s3transfer-0.11.2-py3-none-any.whl (84 kB)\n",
            "Using cached trio-0.28.0-py3-none-any.whl (486 kB)\n",
            "Using cached trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Using cached urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "Using cached validators-0.34.0-py3-none-any.whl (43 kB)\n",
            "Using cached XlsxWriter-3.2.1-py3-none-any.whl (162 kB)\n",
            "Using cached databricks_sdk-0.41.0-py3-none-any.whl (637 kB)\n",
            "Using cached graphql_core-3.2.5-py3-none-any.whl (203 kB)\n",
            "Using cached graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Using cached isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Using cached Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Building wheels for collected packages: faiss-cpu\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for faiss-cpu \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for faiss-cpu (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for faiss-cpu\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build faiss-cpu\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (faiss-cpu)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install datasets 'farm-haystack[all]'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgPvTkoKcR2B"
      },
      "source": [
        "## Loading corpus dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLtj_GyfcRN2",
        "outputId": "61727bc6-ec61-48e7-ab23-15dd5fd31437"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nie mówię, że nie podoba mi się też pomysł szkolenia w miejscu pracy, ale nie możesz oczekiwać, że firma to zrobi. Szkolenie pracowników to nie ich praca – oni tworzą oprogramowanie. Być może systemy edukacyjne w Stanach Zjednoczonych (lub ich studenci) powinny trochę martwić się o zdobycie umiejętności rynkowych w zamian za ich ogromne inwestycje w edukację, zamiast wychodzić z tysiącami zadłużonych studentów i narzekać, że nie są do niczego wykwalifikowani.\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from datasets import Features, Value\n",
        "\n",
        "# Define schema\n",
        "features_qrels = Features({\n",
        "    \"query-id\": Value(\"string\"),\n",
        "    \"corpus-id\": Value(\"string\"),\n",
        "    \"score\": Value(\"int32\")\n",
        "})\n",
        "\n",
        "qrels = load_dataset(\"clarin-knext/fiqa-pl-qrels\", features=features_qrels)\n",
        "corpus = load_dataset(\"clarin-knext/fiqa-pl\", \"corpus\")\n",
        "queries = load_dataset(\"clarin-knext/fiqa-pl\", \"queries\")\n",
        "\n",
        "queries = queries[\"queries\"]\n",
        "corpus = corpus[\"corpus\"]\n",
        "\n",
        "queries_dict = {query[\"_id\"]: query[\"text\"] for query in queries}\n",
        "corpus_dict = {corpus_entry[\"_id\"]: corpus_entry[\"text\"] for corpus_entry in corpus}\n",
        "print(corpus_dict.get('3'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thHKDN9DCKPQ",
        "outputId": "c9e7e546-398e-4e3d-8499-30542d71bbe3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['query-id', 'corpus-id', 'score'],\n",
              "        num_rows: 14166\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['query-id', 'corpus-id', 'score'],\n",
              "        num_rows: 1238\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['query-id', 'corpus-id', 'score'],\n",
              "        num_rows: 1706\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "qrels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5NmXtI_Sguq",
        "outputId": "7b7027d2-0cab-4d33-8b83-69bee8f88ef1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['_id', 'title', 'text'],\n",
              "    num_rows: 57638\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "queries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJDn5dfVSrjK",
        "outputId": "325873a5-091c-4b81-8aef-654bee52a750"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['_id', 'title', 'text'],\n",
              "    num_rows: 6648\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAWs8kbJa8u0"
      },
      "source": [
        "## Creating FAISSDocumentStore"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install farm-haystack[faiss]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqJfavvcdeIq",
        "outputId": "4ad1f18f-b7ac-4931-e59b-1deb2665cb30"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: farm-haystack[faiss] in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: boilerpy3 in /usr/local/lib/python3.11/dist-packages (from farm-haystack[faiss]) (1.0.7)\n",
            "Requirement already satisfied: events in /usr/local/lib/python3.11/dist-packages (from farm-haystack[faiss]) (0.5)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from farm-haystack[faiss]) (0.28.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from farm-haystack[faiss]) (4.23.0)\n",
            "Requirement already satisfied: lazy-imports==0.3.1 in /usr/local/lib/python3.11/dist-packages (from farm-haystack[faiss]) (0.3.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from farm-haystack[faiss]) (10.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from farm-haystack[faiss]) (3.4.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from farm-haystack[faiss]) (2.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from farm-haystack[faiss]) (9.0.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from farm-haystack[faiss]) (4.3.6)\n",
            "Requirement already satisfied: posthog in /usr/local/lib/python3.11/dist-packages (from farm-haystack[faiss]) (3.9.3)\n",
            "Requirement already satisfied: prompthub-py==4.0.0 in /usr/local/lib/python3.11/dist-packages (from farm-haystack[faiss]) (4.0.0)\n",
            "Requirement already satisfied: pydantic<2 in /usr/local/lib/python3.11/dist-packages (from farm-haystack[faiss]) (1.10.21)\n",
            "Requirement already satisfied: quantulum3 in /usr/local/lib/python3.11/dist-packages (from farm-haystack[faiss]) (0.9.2)\n",
            "Requirement already satisfied: rank-bm25 in /usr/local/lib/python3.11/dist-packages (from farm-haystack[faiss]) (0.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from farm-haystack[faiss]) (2.32.3)\n",
            "Requirement already satisfied: requests-cache<1.0.0 in /usr/local/lib/python3.11/dist-packages (from farm-haystack[faiss]) (0.9.8)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from farm-haystack[faiss]) (1.6.0)\n",
            "Requirement already satisfied: sseclient-py in /usr/local/lib/python3.11/dist-packages (from farm-haystack[faiss]) (1.8.0)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.11/dist-packages (from farm-haystack[faiss]) (9.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from farm-haystack[faiss]) (0.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from farm-haystack[faiss]) (4.67.1)\n",
            "Requirement already satisfied: transformers<5.0,>=4.46 in /usr/local/lib/python3.11/dist-packages (from farm-haystack[faiss]) (4.47.1)\n",
            "Collecting faiss-cpu<=1.7.2,>=1.6.3 (from farm-haystack[faiss])\n",
            "  Using cached faiss-cpu-1.7.2.tar.gz (42 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting psycopg2-binary (from farm-haystack[faiss])\n",
            "  Using cached psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting sqlalchemy-utils (from farm-haystack[faiss])\n",
            "  Using cached SQLAlchemy_Utils-0.41.2-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting sqlalchemy<2,>=1.4.2 (from farm-haystack[faiss])\n",
            "  Using cached SQLAlchemy-1.4.54-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from prompthub-py==4.0.0->farm-haystack[faiss]) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2->farm-haystack[faiss]) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->farm-haystack[faiss]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->farm-haystack[faiss]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->farm-haystack[faiss]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->farm-haystack[faiss]) (2024.12.14)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.11/dist-packages (from requests-cache<1.0.0->farm-haystack[faiss]) (1.4.4)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.11/dist-packages (from requests-cache<1.0.0->farm-haystack[faiss]) (24.3.0)\n",
            "Requirement already satisfied: cattrs>=22.2 in /usr/local/lib/python3.11/dist-packages (from requests-cache<1.0.0->farm-haystack[faiss]) (24.1.2)\n",
            "Requirement already satisfied: url-normalize>=1.4 in /usr/local/lib/python3.11/dist-packages (from requests-cache<1.0.0->farm-haystack[faiss]) (1.4.3)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->farm-haystack[faiss]) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->farm-haystack[faiss]) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->farm-haystack[faiss]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->farm-haystack[faiss]) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<2,>=1.4.2->farm-haystack[faiss]) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.5.1->farm-haystack[faiss]) (2024.11.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers<5.0,>=4.46->farm-haystack[faiss]) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0,>=4.46->farm-haystack[faiss]) (0.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0,>=4.46->farm-haystack[faiss]) (24.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0,>=4.46->farm-haystack[faiss]) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0,>=4.46->farm-haystack[faiss]) (0.5.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->farm-haystack[faiss]) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->farm-haystack[faiss]) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->farm-haystack[faiss]) (0.14.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->farm-haystack[faiss]) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->farm-haystack[faiss]) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->farm-haystack[faiss]) (0.22.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->farm-haystack[faiss]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->farm-haystack[faiss]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->farm-haystack[faiss]) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog->farm-haystack[faiss]) (1.17.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog->farm-haystack[faiss]) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog->farm-haystack[faiss]) (2.2.1)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.11/dist-packages (from quantulum3->farm-haystack[faiss]) (7.5.0)\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.11/dist-packages (from quantulum3->farm-haystack[faiss]) (0.5.14)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers<5.0,>=4.46->farm-haystack[faiss]) (2024.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->farm-haystack[faiss]) (1.3.1)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from inflect->quantulum3->farm-haystack[faiss]) (4.4.1)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from num2words->quantulum3->farm-haystack[faiss]) (0.6.2)\n",
            "Using cached SQLAlchemy-1.4.54-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "Using cached psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Using cached SQLAlchemy_Utils-0.41.2-py3-none-any.whl (93 kB)\n",
            "Building wheels for collected packages: faiss-cpu\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for faiss-cpu \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for faiss-cpu (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for faiss-cpu\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build faiss-cpu\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (faiss-cpu)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "x9LtSivIam1X",
        "outputId": "5adef0c4-72fb-4901-b4f7-7fa15a363ae7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'FAISSDocumentStore' from 'haystack.document_stores' (/usr/local/lib/python3.11/dist-packages/haystack/document_stores/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-418fe6a906be>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhaystack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_stores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFAISSDocumentStore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhaystack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdocument_store\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFAISSDocumentStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaiss_index_factory_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Flat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'FAISSDocumentStore' from 'haystack.document_stores' (/usr/local/lib/python3.11/dist-packages/haystack/document_stores/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from haystack.document_stores import FAISSDocumentStore\n",
        "from haystack.schema import Document\n",
        "\n",
        "\n",
        "document_store = FAISSDocumentStore(faiss_index_factory_str=\"Flat\")\n",
        "\n",
        "documents = []\n",
        "\n",
        "for doc in corpus:\n",
        "  content = f'passage: {doc[\"text\"]}'\n",
        "  documents.append(Document(content=content, id=str(doc[\"_id\"])))\n",
        "\n",
        "\n",
        "\n",
        "document_store.write_documents(documents, batch_size=500)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jug812OKbisn"
      },
      "source": [
        "## Creating Multilingual E5 retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkaK3fxRbjGB",
        "outputId": "4d56d294-5543-4326-c4b7-27eb3e31abec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Updating Embedding:   0%|          | 0/57638 [00:00<?, ? docs/s]\n",
            "Inferencing Samples:   0%|          | 0/313 [00:00<?, ? Batches/s]\u001b[A\n",
            "Inferencing Samples:   0%|          | 1/313 [00:00<04:52,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:   1%|          | 2/313 [00:01<04:38,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   1%|          | 3/313 [00:02<04:37,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   1%|▏         | 4/313 [00:03<04:34,  1.13 Batches/s]\u001b[A\n",
            "Inferencing Samples:   2%|▏         | 5/313 [00:04<04:54,  1.05 Batches/s]\u001b[A\n",
            "Inferencing Samples:   2%|▏         | 6/313 [00:05<05:12,  1.02s/ Batches]\u001b[A\n",
            "Inferencing Samples:   2%|▏         | 7/313 [00:07<05:50,  1.15s/ Batches]\u001b[A\n",
            "Inferencing Samples:   3%|▎         | 8/313 [00:08<05:28,  1.08s/ Batches]\u001b[A\n",
            "Inferencing Samples:   3%|▎         | 9/313 [00:09<05:12,  1.03s/ Batches]\u001b[A\n",
            "Inferencing Samples:   3%|▎         | 10/313 [00:09<05:00,  1.01 Batches/s]\u001b[A\n",
            "Inferencing Samples:   4%|▎         | 11/313 [00:10<04:49,  1.04 Batches/s]\u001b[A\n",
            "Inferencing Samples:   4%|▍         | 12/313 [00:11<04:40,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:   4%|▍         | 13/313 [00:12<04:35,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   4%|▍         | 14/313 [00:13<04:31,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   5%|▍         | 15/313 [00:14<04:28,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   5%|▌         | 16/313 [00:15<04:27,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   5%|▌         | 17/313 [00:16<04:25,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   6%|▌         | 18/313 [00:17<04:23,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   6%|▌         | 19/313 [00:17<04:23,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   6%|▋         | 20/313 [00:18<04:22,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   7%|▋         | 21/313 [00:19<04:20,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   7%|▋         | 22/313 [00:20<04:19,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   7%|▋         | 23/313 [00:21<04:20,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   8%|▊         | 24/313 [00:22<04:22,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   8%|▊         | 25/313 [00:23<04:23,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   8%|▊         | 26/313 [00:24<04:23,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   9%|▊         | 27/313 [00:25<04:23,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   9%|▉         | 28/313 [00:26<04:21,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   9%|▉         | 29/313 [00:27<04:18,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  10%|▉         | 30/313 [00:27<04:17,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  10%|▉         | 31/313 [00:28<04:16,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  10%|█         | 32/313 [00:29<04:15,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  11%|█         | 33/313 [00:30<04:15,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  11%|█         | 34/313 [00:31<04:14,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  11%|█         | 35/313 [00:32<04:14,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  12%|█▏        | 36/313 [00:33<04:13,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  12%|█▏        | 37/313 [00:34<04:12,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  12%|█▏        | 38/313 [00:35<04:13,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  12%|█▏        | 39/313 [00:36<04:14,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  13%|█▎        | 40/313 [00:37<04:14,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  13%|█▎        | 41/313 [00:38<04:14,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  13%|█▎        | 42/313 [00:39<04:14,  1.06 Batches/s]\u001b[A\n",
            "Inferencing Samples:  14%|█▎        | 43/313 [00:40<04:13,  1.06 Batches/s]\u001b[A\n",
            "Inferencing Samples:  14%|█▍        | 44/313 [00:40<04:11,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  14%|█▍        | 45/313 [00:41<04:08,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  15%|█▍        | 46/313 [00:42<04:07,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  15%|█▌        | 47/313 [00:43<04:05,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  15%|█▌        | 48/313 [00:44<04:04,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  16%|█▌        | 49/313 [00:45<04:03,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  16%|█▌        | 50/313 [00:46<04:01,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  16%|█▋        | 51/313 [00:47<04:00,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  17%|█▋        | 52/313 [00:48<03:59,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  17%|█▋        | 53/313 [00:49<03:58,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  17%|█▋        | 54/313 [00:50<03:57,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  18%|█▊        | 55/313 [00:51<03:58,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  18%|█▊        | 56/313 [00:51<03:58,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  18%|█▊        | 57/313 [00:52<03:57,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  19%|█▊        | 58/313 [00:53<03:57,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  19%|█▉        | 59/313 [00:54<03:57,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  19%|█▉        | 60/313 [00:55<03:55,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  19%|█▉        | 61/313 [00:56<03:52,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  20%|█▉        | 62/313 [00:57<03:51,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  20%|██        | 63/313 [00:58<03:49,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  20%|██        | 64/313 [00:59<03:48,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  21%|██        | 65/313 [01:00<03:46,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  21%|██        | 66/313 [01:01<03:45,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  21%|██▏       | 67/313 [01:02<03:44,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  22%|██▏       | 68/313 [01:02<03:43,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  22%|██▏       | 69/313 [01:03<03:42,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  22%|██▏       | 70/313 [01:04<03:42,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  23%|██▎       | 71/313 [01:05<03:42,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  23%|██▎       | 72/313 [01:06<03:41,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  23%|██▎       | 73/313 [01:07<03:42,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  24%|██▎       | 74/313 [01:08<03:42,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  24%|██▍       | 75/313 [01:09<03:40,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  24%|██▍       | 76/313 [01:10<03:37,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  25%|██▍       | 77/313 [01:11<03:35,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  25%|██▍       | 78/313 [01:12<03:33,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  25%|██▌       | 79/313 [01:13<03:32,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  26%|██▌       | 80/313 [01:13<03:29,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  26%|██▌       | 81/313 [01:14<03:28,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  26%|██▌       | 82/313 [01:15<03:27,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  27%|██▋       | 83/313 [01:16<03:28,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  27%|██▋       | 84/313 [01:17<03:26,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  27%|██▋       | 85/313 [01:18<03:25,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  27%|██▋       | 86/313 [01:19<03:26,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  28%|██▊       | 87/313 [01:20<03:26,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  28%|██▊       | 88/313 [01:21<03:26,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  28%|██▊       | 89/313 [01:22<03:25,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  29%|██▉       | 90/313 [01:23<03:25,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  29%|██▉       | 91/313 [01:24<03:23,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  29%|██▉       | 92/313 [01:24<03:22,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  30%|██▉       | 93/313 [01:25<03:20,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  30%|███       | 94/313 [01:26<03:17,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  30%|███       | 95/313 [01:27<03:17,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  31%|███       | 96/313 [01:28<03:16,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  31%|███       | 97/313 [01:29<03:14,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  31%|███▏      | 98/313 [01:30<03:13,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  32%|███▏      | 99/313 [01:31<03:12,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  32%|███▏      | 100/313 [01:32<03:12,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  32%|███▏      | 101/313 [01:33<03:11,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  33%|███▎      | 102/313 [01:33<03:11,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  33%|███▎      | 103/313 [01:34<03:10,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  33%|███▎      | 104/313 [01:35<03:10,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  34%|███▎      | 105/313 [01:36<03:10,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  34%|███▍      | 106/313 [01:37<03:10,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  34%|███▍      | 107/313 [01:38<03:08,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  35%|███▍      | 108/313 [01:39<03:06,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  35%|███▍      | 109/313 [01:40<03:05,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  35%|███▌      | 110/313 [01:41<03:03,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  35%|███▌      | 111/313 [01:42<03:02,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  36%|███▌      | 112/313 [01:43<03:00,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  36%|███▌      | 113/313 [01:43<02:59,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  36%|███▋      | 114/313 [01:44<02:58,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  37%|███▋      | 115/313 [01:45<02:57,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  37%|███▋      | 116/313 [01:46<02:57,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  37%|███▋      | 117/313 [01:47<02:56,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  38%|███▊      | 118/313 [01:48<02:57,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  38%|███▊      | 119/313 [01:49<02:57,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  38%|███▊      | 120/313 [01:50<02:57,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  39%|███▊      | 121/313 [01:51<02:57,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  39%|███▉      | 122/313 [01:52<02:56,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  39%|███▉      | 123/313 [01:53<02:54,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  40%|███▉      | 124/313 [01:53<02:52,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  40%|███▉      | 125/313 [01:54<02:50,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  40%|████      | 126/313 [01:55<02:48,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  41%|████      | 127/313 [01:56<02:48,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  41%|████      | 128/313 [01:57<02:46,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  41%|████      | 129/313 [01:58<02:45,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  42%|████▏     | 130/313 [01:59<02:45,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  42%|████▏     | 131/313 [02:00<02:43,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  42%|████▏     | 132/313 [02:01<02:42,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  42%|████▏     | 133/313 [02:02<02:41,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  43%|████▎     | 134/313 [02:02<02:40,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  43%|████▎     | 135/313 [02:03<02:41,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  43%|████▎     | 136/313 [02:04<02:41,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  44%|████▍     | 137/313 [02:05<02:41,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  44%|████▍     | 138/313 [02:06<02:41,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  44%|████▍     | 139/313 [02:07<02:41,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  45%|████▍     | 140/313 [02:08<02:39,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  45%|████▌     | 141/313 [02:09<02:38,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  45%|████▌     | 142/313 [02:10<02:36,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  46%|████▌     | 143/313 [02:11<02:34,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  46%|████▌     | 144/313 [02:12<02:33,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  46%|████▋     | 145/313 [02:13<02:32,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  47%|████▋     | 146/313 [02:13<02:30,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  47%|████▋     | 147/313 [02:14<02:29,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  47%|████▋     | 148/313 [02:15<02:28,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  48%|████▊     | 149/313 [02:16<02:28,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  48%|████▊     | 150/313 [02:17<02:27,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  48%|████▊     | 151/313 [02:18<02:27,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  49%|████▊     | 152/313 [02:19<02:27,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  49%|████▉     | 153/313 [02:20<02:26,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  49%|████▉     | 154/313 [02:21<02:26,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  50%|████▉     | 155/313 [02:22<02:26,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  50%|████▉     | 156/313 [02:23<02:24,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  50%|█████     | 157/313 [02:23<02:22,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  50%|█████     | 158/313 [02:24<02:21,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  51%|█████     | 159/313 [02:25<02:19,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  51%|█████     | 160/313 [02:26<02:19,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  51%|█████▏    | 161/313 [02:27<02:18,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  52%|█████▏    | 162/313 [02:28<02:17,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  52%|█████▏    | 163/313 [02:29<02:16,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  52%|█████▏    | 164/313 [02:30<02:15,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  53%|█████▎    | 165/313 [02:31<02:14,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  53%|█████▎    | 166/313 [02:32<02:13,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  53%|█████▎    | 167/313 [02:33<02:13,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  54%|█████▎    | 168/313 [02:34<02:13,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  54%|█████▍    | 169/313 [02:34<02:12,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  54%|█████▍    | 170/313 [02:35<02:12,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  55%|█████▍    | 171/313 [02:36<02:12,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  55%|█████▍    | 172/313 [02:37<02:10,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  55%|█████▌    | 173/313 [02:38<02:08,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  56%|█████▌    | 174/313 [02:39<02:07,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  56%|█████▌    | 175/313 [02:40<02:06,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  56%|█████▌    | 176/313 [02:41<02:04,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  57%|█████▋    | 177/313 [02:42<02:03,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  57%|█████▋    | 178/313 [02:43<02:02,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  57%|█████▋    | 179/313 [02:44<02:00,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  58%|█████▊    | 180/313 [02:44<02:00,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  58%|█████▊    | 181/313 [02:45<01:58,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  58%|█████▊    | 182/313 [02:46<01:58,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  58%|█████▊    | 183/313 [02:47<01:58,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  59%|█████▉    | 184/313 [02:48<01:57,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  59%|█████▉    | 185/313 [02:49<01:57,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  59%|█████▉    | 186/313 [02:50<01:56,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  60%|█████▉    | 187/313 [02:51<01:55,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  60%|██████    | 188/313 [02:52<01:53,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  60%|██████    | 189/313 [02:53<01:53,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  61%|██████    | 190/313 [02:54<01:51,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  61%|██████    | 191/313 [02:55<01:50,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  61%|██████▏   | 192/313 [02:55<01:49,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  62%|██████▏   | 193/313 [02:56<01:48,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  62%|██████▏   | 194/313 [02:57<01:47,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  62%|██████▏   | 195/313 [02:58<01:46,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  63%|██████▎   | 196/313 [02:59<01:45,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  63%|██████▎   | 197/313 [03:00<01:44,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  63%|██████▎   | 198/313 [03:01<01:43,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  64%|██████▎   | 199/313 [03:02<01:43,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  64%|██████▍   | 200/313 [03:03<01:43,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  64%|██████▍   | 201/313 [03:04<01:42,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  65%|██████▍   | 202/313 [03:05<01:42,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  65%|██████▍   | 203/313 [03:05<01:40,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  65%|██████▌   | 204/313 [03:06<01:39,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  65%|██████▌   | 205/313 [03:07<01:37,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  66%|██████▌   | 206/313 [03:08<01:36,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  66%|██████▌   | 207/313 [03:09<01:36,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  66%|██████▋   | 208/313 [03:10<01:34,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  67%|██████▋   | 209/313 [03:11<01:33,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  67%|██████▋   | 210/313 [03:12<01:32,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  67%|██████▋   | 211/313 [03:13<01:32,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  68%|██████▊   | 212/313 [03:14<01:31,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  68%|██████▊   | 213/313 [03:14<01:30,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  68%|██████▊   | 214/313 [03:15<01:30,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  69%|██████▊   | 215/313 [03:16<01:30,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  69%|██████▉   | 216/313 [03:17<01:29,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  69%|██████▉   | 217/313 [03:18<01:28,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  70%|██████▉   | 218/313 [03:19<01:28,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  70%|██████▉   | 219/313 [03:20<01:27,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  70%|███████   | 220/313 [03:21<01:25,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  71%|███████   | 221/313 [03:22<01:23,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  71%|███████   | 222/313 [03:23<01:22,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  71%|███████   | 223/313 [03:24<01:21,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  72%|███████▏  | 224/313 [03:25<01:20,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  72%|███████▏  | 225/313 [03:25<01:19,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  72%|███████▏  | 226/313 [03:26<01:18,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  73%|███████▎  | 227/313 [03:27<01:17,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  73%|███████▎  | 228/313 [03:28<01:16,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  73%|███████▎  | 229/313 [03:29<01:15,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  73%|███████▎  | 230/313 [03:30<01:14,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  74%|███████▍  | 231/313 [03:31<01:14,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  74%|███████▍  | 232/313 [03:32<01:14,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  74%|███████▍  | 233/313 [03:33<01:13,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  75%|███████▍  | 234/313 [03:34<01:12,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  75%|███████▌  | 235/313 [03:35<01:12,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  75%|███████▌  | 236/313 [03:35<01:10,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  76%|███████▌  | 237/313 [03:36<01:09,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  76%|███████▌  | 238/313 [03:37<01:08,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  76%|███████▋  | 239/313 [03:38<01:07,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  77%|███████▋  | 240/313 [03:39<01:06,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  77%|███████▋  | 241/313 [03:40<01:05,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  77%|███████▋  | 242/313 [03:41<01:04,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  78%|███████▊  | 243/313 [03:42<01:02,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  78%|███████▊  | 244/313 [03:43<01:02,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  78%|███████▊  | 245/313 [03:44<01:01,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  79%|███████▊  | 246/313 [03:45<01:00,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  79%|███████▉  | 247/313 [03:45<01:00,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  79%|███████▉  | 248/313 [03:46<00:59,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  80%|███████▉  | 249/313 [03:47<00:58,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  80%|███████▉  | 250/313 [03:48<00:57,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  80%|████████  | 251/313 [03:49<00:57,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  81%|████████  | 252/313 [03:50<00:56,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  81%|████████  | 253/313 [03:51<00:55,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  81%|████████  | 254/313 [03:52<00:53,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  81%|████████▏ | 255/313 [03:53<00:52,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  82%|████████▏ | 256/313 [03:54<00:51,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  82%|████████▏ | 257/313 [03:55<00:50,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  82%|████████▏ | 258/313 [03:56<00:49,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  83%|████████▎ | 259/313 [03:56<00:48,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  83%|████████▎ | 260/313 [03:57<00:47,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  83%|████████▎ | 261/313 [03:58<00:46,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  84%|████████▎ | 262/313 [03:59<00:46,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  84%|████████▍ | 263/313 [04:00<00:45,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  84%|████████▍ | 264/313 [04:01<00:45,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  85%|████████▍ | 265/313 [04:02<00:44,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  85%|████████▍ | 266/313 [04:03<00:43,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  85%|████████▌ | 267/313 [04:04<00:42,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  86%|████████▌ | 268/313 [04:05<00:41,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  86%|████████▌ | 269/313 [04:06<00:40,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  86%|████████▋ | 270/313 [04:06<00:39,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  87%|████████▋ | 271/313 [04:07<00:38,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  87%|████████▋ | 272/313 [04:08<00:37,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  87%|████████▋ | 273/313 [04:09<00:36,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  88%|████████▊ | 274/313 [04:10<00:35,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  88%|████████▊ | 275/313 [04:11<00:34,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  88%|████████▊ | 276/313 [04:12<00:33,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  88%|████████▊ | 277/313 [04:13<00:32,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  89%|████████▉ | 278/313 [04:14<00:31,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  89%|████████▉ | 279/313 [04:15<00:30,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  89%|████████▉ | 280/313 [04:16<00:30,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  90%|████████▉ | 281/313 [04:17<00:29,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  90%|█████████ | 282/313 [04:17<00:28,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  90%|█████████ | 283/313 [04:18<00:27,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  91%|█████████ | 284/313 [04:19<00:26,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  91%|█████████ | 285/313 [04:20<00:25,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  91%|█████████▏| 286/313 [04:21<00:24,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  92%|█████████▏| 287/313 [04:22<00:23,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  92%|█████████▏| 288/313 [04:23<00:22,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  92%|█████████▏| 289/313 [04:24<00:21,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  93%|█████████▎| 290/313 [04:25<00:20,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  93%|█████████▎| 291/313 [04:26<00:19,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  93%|█████████▎| 292/313 [04:26<00:18,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  94%|█████████▎| 293/313 [04:27<00:18,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  94%|█████████▍| 294/313 [04:28<00:17,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  94%|█████████▍| 295/313 [04:29<00:16,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  95%|█████████▍| 296/313 [04:30<00:15,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  95%|█████████▍| 297/313 [04:31<00:14,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  95%|█████████▌| 298/313 [04:32<00:13,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  96%|█████████▌| 299/313 [04:33<00:13,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  96%|█████████▌| 300/313 [04:34<00:12,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  96%|█████████▌| 301/313 [04:35<00:11,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  96%|█████████▋| 302/313 [04:36<00:10,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  97%|█████████▋| 303/313 [04:37<00:09,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  97%|█████████▋| 304/313 [04:38<00:08,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  97%|█████████▋| 305/313 [04:38<00:07,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  98%|█████████▊| 306/313 [04:39<00:06,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  98%|█████████▊| 307/313 [04:40<00:05,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  98%|█████████▊| 308/313 [04:41<00:04,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  99%|█████████▊| 309/313 [04:42<00:03,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  99%|█████████▉| 310/313 [04:43<00:02,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  99%|█████████▉| 311/313 [04:44<00:01,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples: 100%|█████████▉| 312/313 [04:45<00:00,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples: 100%|██████████| 313/313 [04:45<00:00,  1.10 Batches/s]\n",
            "Documents Processed:  17%|█▋        | 10000/57638 [05:02<24:02, 33.02 docs/s]\n",
            "Documents Processed:  17%|█▋        | 10000/57638 [05:14<24:02, 33.02 docs/s]\n",
            "Inferencing Samples:   0%|          | 1/313 [00:00<05:07,  1.01 Batches/s]\u001b[A\n",
            "Inferencing Samples:   1%|          | 2/313 [00:01<04:50,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:   1%|          | 3/313 [00:02<04:43,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   1%|▏         | 4/313 [00:03<04:39,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   2%|▏         | 5/313 [00:04<04:36,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   2%|▏         | 6/313 [00:05<04:36,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   2%|▏         | 7/313 [00:06<04:34,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   3%|▎         | 8/313 [00:07<04:33,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   3%|▎         | 9/313 [00:08<04:32,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   3%|▎         | 10/313 [00:09<04:31,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   4%|▎         | 11/313 [00:09<04:30,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   4%|▍         | 12/313 [00:10<04:29,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   4%|▍         | 13/313 [00:11<04:30,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   4%|▍         | 14/313 [00:12<04:33,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   5%|▍         | 15/313 [00:13<04:32,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   5%|▌         | 16/313 [00:14<04:33,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   5%|▌         | 17/313 [00:15<04:34,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:   6%|▌         | 18/313 [00:16<04:32,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:   6%|▌         | 19/313 [00:17<04:30,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   6%|▋         | 20/313 [00:18<04:28,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   7%|▋         | 21/313 [00:19<04:27,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   7%|▋         | 22/313 [00:20<04:25,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   7%|▋         | 23/313 [00:20<04:24,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   8%|▊         | 24/313 [00:21<04:23,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   8%|▊         | 25/313 [00:22<04:23,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   8%|▊         | 26/313 [00:23<04:22,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   9%|▊         | 27/313 [00:24<04:21,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   9%|▉         | 28/313 [00:25<04:21,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   9%|▉         | 29/313 [00:26<04:22,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  10%|▉         | 30/313 [00:27<04:23,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  10%|▉         | 31/313 [00:28<04:24,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  10%|█         | 32/313 [00:29<04:23,  1.06 Batches/s]\u001b[A\n",
            "Inferencing Samples:  11%|█         | 33/313 [00:30<04:21,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  11%|█         | 34/313 [00:31<04:18,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  11%|█         | 35/313 [00:32<04:16,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  12%|█▏        | 36/313 [00:32<04:15,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  12%|█▏        | 37/313 [00:33<04:13,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  12%|█▏        | 38/313 [00:34<04:12,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  12%|█▏        | 39/313 [00:35<04:11,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  13%|█▎        | 40/313 [00:36<04:10,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  13%|█▎        | 41/313 [00:37<04:09,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  13%|█▎        | 42/313 [00:38<04:08,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  14%|█▎        | 43/313 [00:39<04:06,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  14%|█▍        | 44/313 [00:40<04:06,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  14%|█▍        | 45/313 [00:41<04:08,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  15%|█▍        | 46/313 [00:42<04:08,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  15%|█▌        | 47/313 [00:43<04:07,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  15%|█▌        | 48/313 [00:44<04:06,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  16%|█▌        | 49/313 [00:44<04:04,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  16%|█▌        | 50/313 [00:45<04:02,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  16%|█▋        | 51/313 [00:46<03:59,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  17%|█▋        | 52/313 [00:47<03:57,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  17%|█▋        | 53/313 [00:48<03:56,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  17%|█▋        | 54/313 [00:49<03:55,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  18%|█▊        | 55/313 [00:50<03:54,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  18%|█▊        | 56/313 [00:51<03:53,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  18%|█▊        | 57/313 [00:52<03:52,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  19%|█▊        | 58/313 [00:53<03:51,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  19%|█▉        | 59/313 [00:54<03:49,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  19%|█▉        | 60/313 [00:54<03:50,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  19%|█▉        | 61/313 [00:55<03:51,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  20%|█▉        | 62/313 [00:56<03:51,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  20%|██        | 63/313 [00:57<03:50,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  20%|██        | 64/313 [00:58<03:50,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  21%|██        | 65/313 [00:59<03:48,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  21%|██        | 66/313 [01:00<03:45,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  21%|██▏       | 67/313 [01:01<03:44,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  22%|██▏       | 68/313 [01:02<03:42,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  22%|██▏       | 69/313 [01:03<03:40,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  22%|██▏       | 70/313 [01:04<03:39,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  23%|██▎       | 71/313 [01:04<03:38,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  23%|██▎       | 72/313 [01:05<03:36,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  23%|██▎       | 73/313 [01:06<03:35,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  24%|██▎       | 74/313 [01:07<03:35,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  24%|██▍       | 75/313 [01:08<03:33,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  24%|██▍       | 76/313 [01:09<03:33,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  25%|██▍       | 77/313 [01:10<03:34,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  25%|██▍       | 78/313 [01:11<03:35,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  25%|██▌       | 79/313 [01:12<03:34,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  26%|██▌       | 80/313 [01:13<03:33,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  26%|██▌       | 81/313 [01:14<03:31,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  26%|██▌       | 82/313 [01:14<03:28,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  27%|██▋       | 83/313 [01:15<03:27,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  27%|██▋       | 84/313 [01:16<03:26,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  27%|██▋       | 85/313 [01:17<03:24,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  27%|██▋       | 86/313 [01:18<03:23,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  28%|██▊       | 87/313 [01:19<03:22,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  28%|██▊       | 88/313 [01:20<03:20,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  28%|██▊       | 89/313 [01:21<03:19,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  29%|██▉       | 90/313 [01:22<03:19,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  29%|██▉       | 91/313 [01:23<03:18,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  29%|██▉       | 92/313 [01:23<03:16,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  30%|██▉       | 93/313 [01:24<03:17,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  30%|███       | 94/313 [01:25<03:17,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  30%|███       | 95/313 [01:26<03:17,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  31%|███       | 96/313 [01:27<03:17,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  31%|███       | 97/313 [01:28<03:17,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  31%|███▏      | 98/313 [01:29<03:14,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  32%|███▏      | 99/313 [01:30<03:12,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  32%|███▏      | 100/313 [01:31<03:11,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  32%|███▏      | 101/313 [01:32<03:10,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  33%|███▎      | 102/313 [01:32<03:09,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  33%|███▎      | 103/313 [01:33<03:08,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  33%|███▎      | 104/313 [01:34<03:07,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  34%|███▎      | 105/313 [01:35<03:06,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  34%|███▍      | 106/313 [01:36<03:05,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  34%|███▍      | 107/313 [01:37<03:04,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  35%|███▍      | 108/313 [01:38<03:03,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  35%|███▍      | 109/313 [01:39<03:03,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  35%|███▌      | 110/313 [01:40<03:04,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  35%|███▌      | 111/313 [01:41<03:04,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  36%|███▌      | 112/313 [01:41<03:03,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  36%|███▌      | 113/313 [01:42<03:03,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  36%|███▋      | 114/313 [01:43<03:01,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  37%|███▋      | 115/313 [01:44<02:59,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  37%|███▋      | 116/313 [01:45<02:58,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  37%|███▋      | 117/313 [01:46<02:57,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  38%|███▊      | 118/313 [01:47<02:55,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  38%|███▊      | 119/313 [01:48<02:54,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  38%|███▊      | 120/313 [01:49<02:53,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  39%|███▊      | 121/313 [01:50<02:52,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  39%|███▉      | 122/313 [01:51<02:51,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  39%|███▉      | 123/313 [01:51<02:50,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  40%|███▉      | 124/313 [01:52<02:50,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  40%|███▉      | 125/313 [01:53<02:51,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  40%|████      | 126/313 [01:54<02:51,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  41%|████      | 127/313 [01:55<02:51,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  41%|████      | 128/313 [01:56<02:52,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  41%|████      | 129/313 [01:57<02:51,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  42%|████▏     | 130/313 [01:58<02:49,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  42%|████▏     | 131/313 [01:59<02:47,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  42%|████▏     | 132/313 [02:00<02:45,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  42%|████▏     | 133/313 [02:01<02:43,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  43%|████▎     | 134/313 [02:02<02:42,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  43%|████▎     | 135/313 [02:02<02:41,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  43%|████▎     | 136/313 [02:03<02:39,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  44%|████▍     | 137/313 [02:04<02:38,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  44%|████▍     | 138/313 [02:05<02:37,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  44%|████▍     | 139/313 [02:06<02:36,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  45%|████▍     | 140/313 [02:07<02:36,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  45%|████▌     | 141/313 [02:08<02:35,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  45%|████▌     | 142/313 [02:09<02:36,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  46%|████▌     | 143/313 [02:10<02:36,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  46%|████▌     | 144/313 [02:11<02:35,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  46%|████▋     | 145/313 [02:12<02:33,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  47%|████▋     | 146/313 [02:12<02:32,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  47%|████▋     | 147/313 [02:13<02:31,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  47%|████▋     | 148/313 [02:14<02:29,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  48%|████▊     | 149/313 [02:15<02:27,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  48%|████▊     | 150/313 [02:16<02:27,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  48%|████▊     | 151/313 [02:17<02:26,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  49%|████▊     | 152/313 [02:18<02:24,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  49%|████▉     | 153/313 [02:19<02:23,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  49%|████▉     | 154/313 [02:20<02:22,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  50%|████▉     | 155/313 [02:20<02:21,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  50%|████▉     | 156/313 [02:21<02:21,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  50%|█████     | 157/313 [02:22<02:22,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  50%|█████     | 158/313 [02:23<02:23,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  51%|█████     | 159/313 [02:24<02:22,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  51%|█████     | 160/313 [02:25<02:22,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  51%|█████▏    | 161/313 [02:26<02:20,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  52%|█████▏    | 162/313 [02:27<02:18,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  52%|█████▏    | 163/313 [02:28<02:16,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  52%|█████▏    | 164/313 [02:29<02:15,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  53%|█████▎    | 165/313 [02:30<02:14,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  53%|█████▎    | 166/313 [02:31<02:13,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  53%|█████▎    | 167/313 [02:31<02:12,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  54%|█████▎    | 168/313 [02:32<02:11,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  54%|█████▍    | 169/313 [02:33<02:10,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  54%|█████▍    | 170/313 [02:34<02:09,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  55%|█████▍    | 171/313 [02:35<02:08,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  55%|█████▍    | 172/313 [02:36<02:08,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  55%|█████▌    | 173/313 [02:37<02:08,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  56%|█████▌    | 174/313 [02:38<02:08,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  56%|█████▌    | 175/313 [02:39<02:07,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  56%|█████▌    | 176/313 [02:40<02:06,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  57%|█████▋    | 177/313 [02:41<02:05,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  57%|█████▋    | 178/313 [02:42<02:03,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  57%|█████▋    | 179/313 [02:42<02:02,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  58%|█████▊    | 180/313 [02:43<02:00,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  58%|█████▊    | 181/313 [02:44<01:59,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  58%|█████▊    | 182/313 [02:45<01:58,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  58%|█████▊    | 183/313 [02:46<01:57,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  59%|█████▉    | 184/313 [02:47<01:56,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  59%|█████▉    | 185/313 [02:48<01:55,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  59%|█████▉    | 186/313 [02:49<01:54,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  60%|█████▉    | 187/313 [02:50<01:53,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  60%|██████    | 188/313 [02:51<01:53,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  60%|██████    | 189/313 [02:52<01:53,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  61%|██████    | 190/313 [02:53<01:53,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  61%|██████    | 191/313 [02:53<01:52,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  61%|██████▏   | 192/313 [02:54<01:52,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  62%|██████▏   | 193/313 [02:55<01:50,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  62%|██████▏   | 194/313 [02:56<01:48,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  62%|██████▏   | 195/313 [02:57<01:47,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  63%|██████▎   | 196/313 [02:58<01:46,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  63%|██████▎   | 197/313 [02:59<01:44,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  63%|██████▎   | 198/313 [03:00<01:43,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  64%|██████▎   | 199/313 [03:01<01:42,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  64%|██████▍   | 200/313 [03:02<01:41,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  64%|██████▍   | 201/313 [03:02<01:40,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  65%|██████▍   | 202/313 [03:03<01:39,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  65%|██████▍   | 203/313 [03:04<01:39,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  65%|██████▌   | 204/313 [03:05<01:39,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  65%|██████▌   | 205/313 [03:06<01:39,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  66%|██████▌   | 206/313 [03:07<01:40,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  66%|██████▌   | 207/313 [03:08<01:39,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  66%|██████▋   | 208/313 [03:09<01:37,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  67%|██████▋   | 209/313 [03:10<01:36,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  67%|██████▋   | 210/313 [03:11<01:34,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  67%|██████▋   | 211/313 [03:12<01:32,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  68%|██████▊   | 212/313 [03:13<01:31,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  68%|██████▊   | 213/313 [03:13<01:30,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  68%|██████▊   | 214/313 [03:14<01:29,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  69%|██████▊   | 215/313 [03:15<01:28,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  69%|██████▉   | 216/313 [03:16<01:28,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  69%|██████▉   | 217/313 [03:17<01:26,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  70%|██████▉   | 218/313 [03:18<01:25,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  70%|██████▉   | 219/313 [03:19<01:24,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  70%|███████   | 220/313 [03:20<01:24,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  71%|███████   | 221/313 [03:21<01:24,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  71%|███████   | 222/313 [03:22<01:23,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  71%|███████   | 223/313 [03:23<01:22,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  72%|███████▏  | 224/313 [03:24<01:22,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  72%|███████▏  | 225/313 [03:24<01:20,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  72%|███████▏  | 226/313 [03:25<01:19,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  73%|███████▎  | 227/313 [03:26<01:18,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  73%|███████▎  | 228/313 [03:27<01:17,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  73%|███████▎  | 229/313 [03:28<01:16,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  73%|███████▎  | 230/313 [03:29<01:15,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  74%|███████▍  | 231/313 [03:30<01:13,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  74%|███████▍  | 232/313 [03:31<01:13,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  74%|███████▍  | 233/313 [03:32<01:12,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  75%|███████▍  | 234/313 [03:33<01:11,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  75%|███████▌  | 235/313 [03:33<01:10,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  75%|███████▌  | 236/313 [03:34<01:10,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  76%|███████▌  | 237/313 [03:35<01:09,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  76%|███████▌  | 238/313 [03:36<01:08,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  76%|███████▋  | 239/313 [03:37<01:07,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  77%|███████▋  | 240/313 [03:38<01:07,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  77%|███████▋  | 241/313 [03:39<01:06,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  77%|███████▋  | 242/313 [03:40<01:04,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  78%|███████▊  | 243/313 [03:41<01:03,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  78%|███████▊  | 244/313 [03:42<01:02,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  78%|███████▊  | 245/313 [03:43<01:01,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  79%|███████▊  | 246/313 [03:43<01:00,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  79%|███████▉  | 247/313 [03:44<00:59,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  79%|███████▉  | 248/313 [03:45<00:58,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  80%|███████▉  | 249/313 [03:46<00:57,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  80%|███████▉  | 250/313 [03:47<00:56,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  80%|████████  | 251/313 [03:48<00:56,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  81%|████████  | 252/313 [03:49<00:55,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  81%|████████  | 253/313 [03:50<00:54,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  81%|████████  | 254/313 [03:51<00:54,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  81%|████████▏ | 255/313 [03:52<00:53,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  82%|████████▏ | 256/313 [03:53<00:52,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  82%|████████▏ | 257/313 [03:54<00:52,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  82%|████████▏ | 258/313 [03:55<00:51,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  83%|████████▎ | 259/313 [03:55<00:49,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  83%|████████▎ | 260/313 [03:56<00:48,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  83%|████████▎ | 261/313 [03:57<00:47,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  84%|████████▎ | 262/313 [03:58<00:46,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  84%|████████▍ | 263/313 [03:59<00:45,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  84%|████████▍ | 264/313 [04:00<00:44,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  85%|████████▍ | 265/313 [04:01<00:43,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  85%|████████▍ | 266/313 [04:02<00:42,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  85%|████████▌ | 267/313 [04:03<00:41,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  86%|████████▌ | 268/313 [04:04<00:40,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  86%|████████▌ | 269/313 [04:05<00:40,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  86%|████████▋ | 270/313 [04:05<00:39,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  87%|████████▋ | 271/313 [04:06<00:39,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  87%|████████▋ | 272/313 [04:07<00:38,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  87%|████████▋ | 273/313 [04:08<00:37,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  88%|████████▊ | 274/313 [04:09<00:36,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  88%|████████▊ | 275/313 [04:10<00:34,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  88%|████████▊ | 276/313 [04:11<00:33,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  88%|████████▊ | 277/313 [04:12<00:32,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  89%|████████▉ | 278/313 [04:13<00:31,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  89%|████████▉ | 279/313 [04:14<00:30,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  89%|████████▉ | 280/313 [04:15<00:29,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  90%|████████▉ | 281/313 [04:15<00:28,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  90%|█████████ | 282/313 [04:16<00:27,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  90%|█████████ | 283/313 [04:17<00:27,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  91%|█████████ | 284/313 [04:18<00:26,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  91%|█████████ | 285/313 [04:19<00:25,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  91%|█████████▏| 286/313 [04:20<00:24,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  92%|█████████▏| 287/313 [04:21<00:24,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  92%|█████████▏| 288/313 [04:22<00:23,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  92%|█████████▏| 289/313 [04:23<00:22,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  93%|█████████▎| 290/313 [04:24<00:21,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  93%|█████████▎| 291/313 [04:25<00:20,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  93%|█████████▎| 292/313 [04:26<00:19,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  94%|█████████▎| 293/313 [04:26<00:18,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  94%|█████████▍| 294/313 [04:27<00:17,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  94%|█████████▍| 295/313 [04:28<00:16,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  95%|█████████▍| 296/313 [04:29<00:15,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  95%|█████████▍| 297/313 [04:30<00:14,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  95%|█████████▌| 298/313 [04:31<00:13,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  96%|█████████▌| 299/313 [04:32<00:12,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  96%|█████████▌| 300/313 [04:33<00:11,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  96%|█████████▌| 301/313 [04:34<00:10,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  96%|█████████▋| 302/313 [04:35<00:10,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  97%|█████████▋| 303/313 [04:36<00:09,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  97%|█████████▋| 304/313 [04:37<00:08,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  97%|█████████▋| 305/313 [04:37<00:07,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  98%|█████████▊| 306/313 [04:38<00:06,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  98%|█████████▊| 307/313 [04:39<00:05,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  98%|█████████▊| 308/313 [04:40<00:04,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  99%|█████████▊| 309/313 [04:41<00:03,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  99%|█████████▉| 310/313 [04:42<00:02,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  99%|█████████▉| 311/313 [04:43<00:01,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples: 100%|█████████▉| 312/313 [04:44<00:00,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples: 100%|██████████| 313/313 [04:44<00:00,  1.10 Batches/s]\n",
            "Documents Processed:  35%|███▍      | 20000/57638 [10:02<18:51, 33.25 docs/s]\n",
            "Documents Processed:  35%|███▍      | 20000/57638 [10:14<18:51, 33.25 docs/s]\n",
            "Inferencing Samples:   0%|          | 1/313 [00:00<04:59,  1.04 Batches/s]\u001b[A\n",
            "Inferencing Samples:   1%|          | 2/313 [00:01<04:43,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   1%|          | 3/313 [00:02<04:40,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   1%|▏         | 4/313 [00:03<04:40,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   2%|▏         | 5/313 [00:04<04:38,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   2%|▏         | 6/313 [00:05<04:40,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   2%|▏         | 7/313 [00:06<04:39,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   3%|▎         | 8/313 [00:07<04:39,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   3%|▎         | 9/313 [00:08<04:35,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   3%|▎         | 10/313 [00:09<04:33,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   4%|▎         | 11/313 [00:09<04:32,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   4%|▍         | 12/313 [00:10<04:30,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   4%|▍         | 13/313 [00:11<04:29,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   4%|▍         | 14/313 [00:12<04:28,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   5%|▍         | 15/313 [00:13<04:27,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   5%|▌         | 16/313 [00:14<04:27,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   5%|▌         | 17/313 [00:15<04:27,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   6%|▌         | 18/313 [00:16<04:26,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   6%|▌         | 19/313 [00:17<04:25,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   6%|▋         | 20/313 [00:18<04:27,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   7%|▋         | 21/313 [00:19<04:28,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   7%|▋         | 22/313 [00:20<04:29,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:   7%|▋         | 23/313 [00:20<04:29,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:   8%|▊         | 24/313 [00:21<04:29,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:   8%|▊         | 25/313 [00:22<04:27,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:   8%|▊         | 26/313 [00:23<04:26,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:   9%|▊         | 27/313 [00:24<04:25,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:   9%|▉         | 28/313 [00:25<04:22,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   9%|▉         | 29/313 [00:26<04:20,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  10%|▉         | 30/313 [00:27<04:19,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  10%|▉         | 31/313 [00:28<04:18,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  10%|█         | 32/313 [00:29<04:17,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  11%|█         | 33/313 [00:30<04:16,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  11%|█         | 34/313 [00:31<04:15,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  11%|█         | 35/313 [00:31<04:14,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  12%|█▏        | 36/313 [00:32<04:15,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  12%|█▏        | 37/313 [00:33<04:15,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  12%|█▏        | 38/313 [00:34<04:15,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  12%|█▏        | 39/313 [00:35<04:16,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  13%|█▎        | 40/313 [00:36<04:13,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  13%|█▎        | 41/313 [00:37<04:11,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  13%|█▎        | 42/313 [00:38<04:09,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  14%|█▎        | 43/313 [00:39<04:07,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  14%|█▍        | 44/313 [00:40<04:06,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  14%|█▍        | 45/313 [00:41<04:05,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  15%|█▍        | 46/313 [00:42<04:03,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  15%|█▌        | 47/313 [00:43<04:02,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  15%|█▌        | 48/313 [00:43<04:01,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  16%|█▌        | 49/313 [00:44<03:59,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  16%|█▌        | 50/313 [00:45<03:58,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  16%|█▋        | 51/313 [00:46<03:59,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  17%|█▋        | 52/313 [00:47<04:00,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  17%|█▋        | 53/313 [00:48<03:59,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  17%|█▋        | 54/313 [00:49<03:59,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  18%|█▊        | 55/313 [00:50<03:58,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  18%|█▊        | 56/313 [00:51<03:55,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  18%|█▊        | 57/313 [00:52<03:53,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  19%|█▊        | 58/313 [00:53<03:52,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  19%|█▉        | 59/313 [00:53<03:50,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  19%|█▉        | 60/313 [00:54<03:50,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  19%|█▉        | 61/313 [00:55<03:48,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  20%|█▉        | 62/313 [00:56<03:48,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  20%|██        | 63/313 [00:57<03:46,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  20%|██        | 64/313 [00:58<03:45,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  21%|██        | 65/313 [00:59<03:43,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  21%|██        | 66/313 [01:00<03:42,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  21%|██▏       | 67/313 [01:01<03:43,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  22%|██▏       | 68/313 [01:02<03:43,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  22%|██▏       | 69/313 [01:03<03:44,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  22%|██▏       | 70/313 [01:04<03:44,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  23%|██▎       | 71/313 [01:04<03:43,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  23%|██▎       | 72/313 [01:05<03:40,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  23%|██▎       | 73/313 [01:06<03:38,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  24%|██▎       | 74/313 [01:07<03:36,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  24%|██▍       | 75/313 [01:08<03:35,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  24%|██▍       | 76/313 [01:09<03:33,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  25%|██▍       | 77/313 [01:10<03:32,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  25%|██▍       | 78/313 [01:11<03:31,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  25%|██▌       | 79/313 [01:12<03:29,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  26%|██▌       | 80/313 [01:13<03:28,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  26%|██▌       | 81/313 [01:13<03:28,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  26%|██▌       | 82/313 [01:14<03:27,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  27%|██▋       | 83/313 [01:15<03:28,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  27%|██▋       | 84/313 [01:16<03:28,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  27%|██▋       | 85/313 [01:17<03:28,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  27%|██▋       | 86/313 [01:18<03:27,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  28%|██▊       | 87/313 [01:19<03:27,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  28%|██▊       | 88/313 [01:20<03:25,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  28%|██▊       | 89/313 [01:21<03:23,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  29%|██▉       | 90/313 [01:22<03:22,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  29%|██▉       | 91/313 [01:23<03:20,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  29%|██▉       | 92/313 [01:23<03:18,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  30%|██▉       | 93/313 [01:24<03:17,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  30%|███       | 94/313 [01:25<03:16,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  30%|███       | 95/313 [01:26<03:15,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  31%|███       | 96/313 [01:27<03:14,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  31%|███       | 97/313 [01:28<03:12,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  31%|███▏      | 98/313 [01:29<03:11,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  32%|███▏      | 99/313 [01:30<03:11,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  32%|███▏      | 100/313 [01:31<03:11,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  32%|███▏      | 101/313 [01:31<03:11,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  33%|███▎      | 102/313 [01:32<03:11,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  33%|███▎      | 103/313 [01:33<03:11,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  33%|███▎      | 104/313 [01:34<03:11,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  34%|███▎      | 105/313 [01:35<03:09,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  34%|███▍      | 106/313 [01:36<03:07,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  34%|███▍      | 107/313 [01:37<03:05,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  35%|███▍      | 108/313 [01:38<03:04,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  35%|███▍      | 109/313 [01:39<03:02,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  35%|███▌      | 110/313 [01:40<03:01,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  35%|███▌      | 111/313 [01:41<03:00,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  36%|███▌      | 112/313 [01:41<02:59,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  36%|███▌      | 113/313 [01:42<02:58,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  36%|███▋      | 114/313 [01:43<02:57,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  37%|███▋      | 115/313 [01:44<02:57,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  37%|███▋      | 116/313 [01:45<02:57,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  37%|███▋      | 117/313 [01:46<02:58,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  38%|███▊      | 118/313 [01:47<02:57,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  38%|███▊      | 119/313 [01:48<02:58,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  38%|███▊      | 120/313 [01:49<02:56,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  39%|███▊      | 121/313 [01:50<02:54,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  39%|███▉      | 122/313 [01:50<02:53,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  39%|███▉      | 123/313 [01:51<02:51,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  40%|███▉      | 124/313 [01:52<02:50,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  40%|███▉      | 125/313 [01:53<02:49,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  40%|████      | 126/313 [01:54<02:49,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  41%|████      | 127/313 [01:55<02:48,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  41%|████      | 128/313 [01:56<02:46,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  41%|████      | 129/313 [01:57<02:46,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  42%|████▏     | 130/313 [01:58<02:44,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  42%|████▏     | 131/313 [01:59<02:44,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  42%|████▏     | 132/313 [02:00<02:44,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  42%|████▏     | 133/313 [02:00<02:44,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  43%|████▎     | 134/313 [02:01<02:44,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  43%|████▎     | 135/313 [02:02<02:44,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  43%|████▎     | 136/313 [02:03<02:42,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  44%|████▍     | 137/313 [02:04<02:40,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  44%|████▍     | 138/313 [02:05<02:38,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  44%|████▍     | 139/313 [02:06<02:37,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  45%|████▍     | 140/313 [02:07<02:36,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  45%|████▌     | 141/313 [02:08<02:35,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  45%|████▌     | 142/313 [02:09<02:34,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  46%|████▌     | 143/313 [02:10<02:33,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  46%|████▌     | 144/313 [02:10<02:32,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  46%|████▋     | 145/313 [02:11<02:31,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  47%|████▋     | 146/313 [02:12<02:30,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  47%|████▋     | 147/313 [02:13<02:31,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  47%|████▋     | 148/313 [02:14<02:31,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  48%|████▊     | 149/313 [02:15<02:31,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  48%|████▊     | 150/313 [02:16<02:30,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  48%|████▊     | 151/313 [02:17<02:30,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  49%|████▊     | 152/313 [02:18<02:28,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  49%|████▉     | 153/313 [02:19<02:26,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  49%|████▉     | 154/313 [02:20<02:24,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  50%|████▉     | 155/313 [02:20<02:23,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  50%|████▉     | 156/313 [02:21<02:21,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  50%|█████     | 157/313 [02:22<02:20,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  50%|█████     | 158/313 [02:23<02:20,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  51%|█████     | 159/313 [02:24<02:18,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  51%|█████     | 160/313 [02:25<02:17,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  51%|█████▏    | 161/313 [02:26<02:16,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  52%|█████▏    | 162/313 [02:27<02:15,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  52%|█████▏    | 163/313 [02:28<02:15,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  52%|█████▏    | 164/313 [02:29<02:15,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  53%|█████▎    | 165/313 [02:30<02:15,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  53%|█████▎    | 166/313 [02:30<02:15,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  53%|█████▎    | 167/313 [02:31<02:15,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  54%|█████▎    | 168/313 [02:32<02:13,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  54%|█████▍    | 169/313 [02:33<02:11,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  54%|█████▍    | 170/313 [02:34<02:10,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  55%|█████▍    | 171/313 [02:35<02:08,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  55%|█████▍    | 172/313 [02:36<02:07,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  55%|█████▌    | 173/313 [02:37<02:07,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  56%|█████▌    | 174/313 [02:38<02:05,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  56%|█████▌    | 175/313 [02:39<02:04,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  56%|█████▌    | 176/313 [02:40<02:03,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  57%|█████▋    | 177/313 [02:40<02:02,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  57%|█████▋    | 178/313 [02:41<02:01,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  57%|█████▋    | 179/313 [02:42<02:01,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  58%|█████▊    | 180/313 [02:43<02:01,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  58%|█████▊    | 181/313 [02:44<02:02,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  58%|█████▊    | 182/313 [02:45<02:01,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  58%|█████▊    | 183/313 [02:46<02:00,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  59%|█████▉    | 184/313 [02:47<01:58,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  59%|█████▉    | 185/313 [02:48<01:57,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  59%|█████▉    | 186/313 [02:49<01:55,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  60%|█████▉    | 187/313 [02:50<01:54,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  60%|██████    | 188/313 [02:51<01:53,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  60%|██████    | 189/313 [02:51<01:52,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  61%|██████    | 190/313 [02:52<01:51,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  61%|██████    | 191/313 [02:53<01:50,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  61%|██████▏   | 192/313 [02:54<01:49,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  62%|██████▏   | 193/313 [02:55<01:48,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  62%|██████▏   | 194/313 [02:56<01:47,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  62%|██████▏   | 195/313 [02:57<01:47,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  63%|██████▎   | 196/313 [02:58<01:47,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  63%|██████▎   | 197/313 [02:59<01:47,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  63%|██████▎   | 198/313 [03:00<01:46,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  64%|██████▎   | 199/313 [03:01<01:45,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  64%|██████▍   | 200/313 [03:02<01:43,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  64%|██████▍   | 201/313 [03:02<01:42,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  65%|██████▍   | 202/313 [03:03<01:41,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  65%|██████▍   | 203/313 [03:04<01:39,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  65%|██████▌   | 204/313 [03:05<01:38,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  65%|██████▌   | 205/313 [03:06<01:37,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  66%|██████▌   | 206/313 [03:07<01:36,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  66%|██████▌   | 207/313 [03:08<01:35,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  66%|██████▋   | 208/313 [03:09<01:34,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  67%|██████▋   | 209/313 [03:10<01:33,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  67%|██████▋   | 210/313 [03:11<01:32,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  67%|██████▋   | 211/313 [03:11<01:32,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  68%|██████▊   | 212/313 [03:12<01:31,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  68%|██████▊   | 213/313 [03:13<01:31,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  68%|██████▊   | 214/313 [03:14<01:31,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  69%|██████▊   | 215/313 [03:15<01:30,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  69%|██████▉   | 216/313 [03:16<01:28,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  69%|██████▉   | 217/313 [03:17<01:27,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  70%|██████▉   | 218/313 [03:18<01:26,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  70%|██████▉   | 219/313 [03:19<01:25,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  70%|███████   | 220/313 [03:20<01:24,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  71%|███████   | 221/313 [03:21<01:23,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  71%|███████   | 222/313 [03:21<01:22,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  71%|███████   | 223/313 [03:22<01:20,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  72%|███████▏  | 224/313 [03:23<01:20,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  72%|███████▏  | 225/313 [03:24<01:19,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  72%|███████▏  | 226/313 [03:25<01:18,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  73%|███████▎  | 227/313 [03:26<01:17,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  73%|███████▎  | 228/313 [03:27<01:17,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  73%|███████▎  | 229/313 [03:28<01:17,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  73%|███████▎  | 230/313 [03:29<01:16,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  74%|███████▍  | 231/313 [03:30<01:15,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  74%|███████▍  | 232/313 [03:31<01:14,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  74%|███████▍  | 233/313 [03:31<01:12,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  75%|███████▍  | 234/313 [03:32<01:11,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  75%|███████▌  | 235/313 [03:33<01:10,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  75%|███████▌  | 236/313 [03:34<01:09,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  76%|███████▌  | 237/313 [03:35<01:08,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  76%|███████▌  | 238/313 [03:36<01:07,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  76%|███████▋  | 239/313 [03:37<01:06,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  77%|███████▋  | 240/313 [03:38<01:05,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  77%|███████▋  | 241/313 [03:39<01:04,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  77%|███████▋  | 242/313 [03:40<01:03,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  78%|███████▊  | 243/313 [03:40<01:03,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  78%|███████▊  | 244/313 [03:41<01:03,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  78%|███████▊  | 245/313 [03:42<01:02,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  79%|███████▊  | 246/313 [03:43<01:01,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  79%|███████▉  | 247/313 [03:44<01:00,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  79%|███████▉  | 248/313 [03:45<00:59,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  80%|███████▉  | 249/313 [03:46<00:58,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  80%|███████▉  | 250/313 [03:47<00:57,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  80%|████████  | 251/313 [03:48<00:56,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  81%|████████  | 252/313 [03:49<00:55,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  81%|████████  | 253/313 [03:50<00:54,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  81%|████████  | 254/313 [03:50<00:53,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  81%|████████▏ | 255/313 [03:51<00:52,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  82%|████████▏ | 256/313 [03:52<00:51,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  82%|████████▏ | 257/313 [03:53<00:50,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  82%|████████▏ | 258/313 [03:54<00:49,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  83%|████████▎ | 259/313 [03:55<00:48,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  83%|████████▎ | 260/313 [03:56<00:48,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  83%|████████▎ | 261/313 [03:57<00:47,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  84%|████████▎ | 262/313 [03:58<00:46,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  84%|████████▍ | 263/313 [03:59<00:45,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  84%|████████▍ | 264/313 [04:00<00:44,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  85%|████████▍ | 265/313 [04:00<00:43,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  85%|████████▍ | 266/313 [04:01<00:42,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  85%|████████▌ | 267/313 [04:02<00:41,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  86%|████████▌ | 268/313 [04:03<00:40,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  86%|████████▌ | 269/313 [04:04<00:39,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  86%|████████▋ | 270/313 [04:05<00:38,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  87%|████████▋ | 271/313 [04:06<00:37,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  87%|████████▋ | 272/313 [04:07<00:36,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  87%|████████▋ | 273/313 [04:08<00:36,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  88%|████████▊ | 274/313 [04:09<00:35,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  88%|████████▊ | 275/313 [04:10<00:34,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  88%|████████▊ | 276/313 [04:10<00:33,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  88%|████████▊ | 277/313 [04:11<00:33,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  89%|████████▉ | 278/313 [04:12<00:32,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  89%|████████▉ | 279/313 [04:13<00:31,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  89%|████████▉ | 280/313 [04:14<00:30,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  90%|████████▉ | 281/313 [04:15<00:29,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  90%|█████████ | 282/313 [04:16<00:28,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  90%|█████████ | 283/313 [04:17<00:27,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  91%|█████████ | 284/313 [04:18<00:26,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  91%|█████████ | 285/313 [04:19<00:25,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  91%|█████████▏| 286/313 [04:20<00:24,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  92%|█████████▏| 287/313 [04:20<00:23,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  92%|█████████▏| 288/313 [04:21<00:22,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  92%|█████████▏| 289/313 [04:22<00:21,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  93%|█████████▎| 290/313 [04:23<00:20,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  93%|█████████▎| 291/313 [04:24<00:20,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  93%|█████████▎| 292/313 [04:25<00:19,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  94%|█████████▎| 293/313 [04:26<00:18,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  94%|█████████▍| 294/313 [04:27<00:17,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  94%|█████████▍| 295/313 [04:28<00:16,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  95%|█████████▍| 296/313 [04:29<00:15,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  95%|█████████▍| 297/313 [04:30<00:14,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  95%|█████████▌| 298/313 [04:31<00:13,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  96%|█████████▌| 299/313 [04:31<00:12,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  96%|█████████▌| 300/313 [04:32<00:11,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  96%|█████████▌| 301/313 [04:33<00:10,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  96%|█████████▋| 302/313 [04:34<00:09,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  97%|█████████▋| 303/313 [04:35<00:09,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  97%|█████████▋| 304/313 [04:36<00:08,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  97%|█████████▋| 305/313 [04:37<00:07,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  98%|█████████▊| 306/313 [04:38<00:06,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  98%|█████████▊| 307/313 [04:39<00:05,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  98%|█████████▊| 308/313 [04:40<00:04,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  99%|█████████▊| 309/313 [04:41<00:03,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  99%|█████████▉| 310/313 [04:41<00:02,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  99%|█████████▉| 311/313 [04:42<00:01,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples: 100%|█████████▉| 312/313 [04:43<00:00,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples: 100%|██████████| 313/313 [04:44<00:00,  1.10 Batches/s]\n",
            "Documents Processed:  52%|█████▏    | 30000/57638 [15:01<13:49, 33.33 docs/s]\n",
            "Inferencing Samples:   0%|          | 0/313 [00:00<?, ? Batches/s]\u001b[A\n",
            "Documents Processed:  52%|█████▏    | 30000/57638 [15:14<13:49, 33.33 docs/s]\n",
            "Inferencing Samples:   1%|          | 2/313 [00:01<04:41,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   1%|          | 3/313 [00:02<04:38,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   1%|▏         | 4/313 [00:03<04:36,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   2%|▏         | 5/313 [00:04<04:34,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   2%|▏         | 6/313 [00:05<04:34,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   2%|▏         | 7/313 [00:06<04:32,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   3%|▎         | 8/313 [00:07<04:34,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   3%|▎         | 9/313 [00:08<04:36,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   3%|▎         | 10/313 [00:09<04:37,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   4%|▎         | 11/313 [00:09<04:38,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:   4%|▍         | 12/313 [00:10<04:38,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:   4%|▍         | 13/313 [00:11<04:36,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:   4%|▍         | 14/313 [00:12<04:34,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   5%|▍         | 15/313 [00:13<04:32,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   5%|▌         | 16/313 [00:14<04:31,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   5%|▌         | 17/313 [00:15<04:30,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   6%|▌         | 18/313 [00:16<04:29,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   6%|▌         | 19/313 [00:17<04:28,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   6%|▋         | 20/313 [00:18<04:27,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   7%|▋         | 21/313 [00:19<04:26,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   7%|▋         | 22/313 [00:20<04:26,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   7%|▋         | 23/313 [00:20<04:24,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   8%|▊         | 24/313 [00:21<04:26,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:   8%|▊         | 25/313 [00:22<04:27,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:   8%|▊         | 26/313 [00:23<04:28,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:   9%|▊         | 27/313 [00:24<04:27,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:   9%|▉         | 28/313 [00:25<04:26,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:   9%|▉         | 29/313 [00:26<04:25,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  10%|▉         | 30/313 [00:27<04:23,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  10%|▉         | 31/313 [00:28<04:21,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  10%|█         | 32/313 [00:29<04:19,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  11%|█         | 33/313 [00:30<04:17,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  11%|█         | 34/313 [00:31<04:17,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  11%|█         | 35/313 [00:32<04:16,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  12%|█▏        | 36/313 [00:33<04:13,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  12%|█▏        | 37/313 [00:33<04:12,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  12%|█▏        | 38/313 [00:34<04:11,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  12%|█▏        | 39/313 [00:35<04:12,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  13%|█▎        | 40/313 [00:36<04:12,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  13%|█▎        | 41/313 [00:37<04:13,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  13%|█▎        | 42/313 [00:38<04:13,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  14%|█▎        | 43/313 [00:39<04:13,  1.06 Batches/s]\u001b[A\n",
            "Inferencing Samples:  14%|█▍        | 44/313 [00:40<04:10,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  14%|█▍        | 45/313 [00:41<04:08,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  15%|█▍        | 46/313 [00:42<04:06,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  15%|█▌        | 47/313 [00:43<04:04,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  15%|█▌        | 48/313 [00:44<04:02,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  16%|█▌        | 49/313 [00:45<04:01,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  16%|█▌        | 50/313 [00:45<03:59,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  16%|█▋        | 51/313 [00:46<03:59,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  17%|█▋        | 52/313 [00:47<03:57,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  17%|█▋        | 53/313 [00:48<03:55,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  17%|█▋        | 54/313 [00:49<03:54,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  18%|█▊        | 55/313 [00:50<03:55,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  18%|█▊        | 56/313 [00:51<03:55,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  18%|█▊        | 57/313 [00:52<03:56,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  19%|█▊        | 58/313 [00:53<03:56,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  19%|█▉        | 59/313 [00:54<03:54,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  19%|█▉        | 60/313 [00:55<03:52,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  19%|█▉        | 61/313 [00:56<03:50,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  20%|█▉        | 62/313 [00:56<03:49,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  20%|██        | 63/313 [00:57<03:47,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  20%|██        | 64/313 [00:58<03:46,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  21%|██        | 65/313 [00:59<03:44,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  21%|██        | 66/313 [01:00<03:44,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  21%|██▏       | 67/313 [01:01<03:43,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  22%|██▏       | 68/313 [01:02<03:41,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  22%|██▏       | 69/313 [01:03<03:40,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  22%|██▏       | 70/313 [01:04<03:40,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  23%|██▎       | 71/313 [01:05<03:40,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  23%|██▎       | 72/313 [01:06<03:40,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  23%|██▎       | 73/313 [01:06<03:39,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  24%|██▎       | 74/313 [01:07<03:39,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  24%|██▍       | 75/313 [01:08<03:38,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  24%|██▍       | 76/313 [01:09<03:36,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  25%|██▍       | 77/313 [01:10<03:35,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  25%|██▍       | 78/313 [01:11<03:33,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  25%|██▌       | 79/313 [01:12<03:31,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  26%|██▌       | 80/313 [01:13<03:31,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  26%|██▌       | 81/313 [01:14<03:29,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  26%|██▌       | 82/313 [01:15<03:27,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  27%|██▋       | 83/313 [01:15<03:26,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  27%|██▋       | 84/313 [01:16<03:24,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  27%|██▋       | 85/313 [01:17<03:24,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  27%|██▋       | 86/313 [01:18<03:25,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  28%|██▊       | 87/313 [01:19<03:25,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  28%|██▊       | 88/313 [01:20<03:24,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  28%|██▊       | 89/313 [01:21<03:24,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  29%|██▉       | 90/313 [01:22<03:24,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  29%|██▉       | 91/313 [01:23<03:22,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  29%|██▉       | 92/313 [01:24<03:20,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  30%|██▉       | 93/313 [01:25<03:18,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  30%|███       | 94/313 [01:25<03:16,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  30%|███       | 95/313 [01:26<03:15,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  31%|███       | 96/313 [01:27<03:14,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  31%|███       | 97/313 [01:28<03:13,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  31%|███▏      | 98/313 [01:29<03:13,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  32%|███▏      | 99/313 [01:30<03:12,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  32%|███▏      | 100/313 [01:31<03:11,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  32%|███▏      | 101/313 [01:32<03:09,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  33%|███▎      | 102/313 [01:33<03:10,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  33%|███▎      | 103/313 [01:34<03:11,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  33%|███▎      | 104/313 [01:34<03:10,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  34%|███▎      | 105/313 [01:35<03:10,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  34%|███▍      | 106/313 [01:36<03:11,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  34%|███▍      | 107/313 [01:37<03:08,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  35%|███▍      | 108/313 [01:38<03:06,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  35%|███▍      | 109/313 [01:39<03:04,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  35%|███▌      | 110/313 [01:40<03:02,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  35%|███▌      | 111/313 [01:41<03:01,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  36%|███▌      | 112/313 [01:42<03:00,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  36%|███▌      | 113/313 [01:43<02:58,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  36%|███▋      | 114/313 [01:43<02:58,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  37%|███▋      | 115/313 [01:44<02:57,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  37%|███▋      | 116/313 [01:45<02:57,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  37%|███▋      | 117/313 [01:46<02:56,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  38%|███▊      | 118/313 [01:47<02:56,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  38%|███▊      | 119/313 [01:48<02:56,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  38%|███▊      | 120/313 [01:49<02:56,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  39%|███▊      | 121/313 [01:50<02:56,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  39%|███▉      | 122/313 [01:51<02:54,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  39%|███▉      | 123/313 [01:52<02:52,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  40%|███▉      | 124/313 [01:53<02:51,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  40%|███▉      | 125/313 [01:53<02:50,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  40%|████      | 126/313 [01:54<02:48,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  41%|████      | 127/313 [01:55<02:46,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  41%|████      | 128/313 [01:56<02:45,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  41%|████      | 129/313 [01:57<02:45,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  42%|████▏     | 130/313 [01:58<02:44,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  42%|████▏     | 131/313 [01:59<02:43,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  42%|████▏     | 132/313 [02:00<02:43,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  42%|████▏     | 133/313 [02:01<02:43,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  43%|████▎     | 134/313 [02:02<02:43,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  43%|████▎     | 135/313 [02:03<02:43,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  43%|████▎     | 136/313 [02:03<02:42,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  44%|████▍     | 137/313 [02:04<02:41,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  44%|████▍     | 138/313 [02:05<02:40,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  44%|████▍     | 139/313 [02:06<02:38,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  45%|████▍     | 140/313 [02:07<02:37,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  45%|████▌     | 141/313 [02:08<02:35,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  45%|████▌     | 142/313 [02:09<02:34,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  46%|████▌     | 143/313 [02:10<02:34,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  46%|████▌     | 144/313 [02:11<02:33,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  46%|████▋     | 145/313 [02:12<02:32,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  47%|████▋     | 146/313 [02:13<02:31,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  47%|████▋     | 147/313 [02:13<02:29,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  47%|████▋     | 148/313 [02:14<02:29,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  48%|████▊     | 149/313 [02:15<02:29,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  48%|████▊     | 150/313 [02:16<02:29,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  48%|████▊     | 151/313 [02:17<02:29,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  49%|████▊     | 152/313 [02:18<02:29,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  49%|████▉     | 153/313 [02:19<02:28,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  49%|████▉     | 154/313 [02:20<02:26,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  50%|████▉     | 155/313 [02:21<02:24,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  50%|████▉     | 156/313 [02:22<02:23,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  50%|█████     | 157/313 [02:23<02:21,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  50%|█████     | 158/313 [02:24<02:20,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  51%|█████     | 159/313 [02:24<02:19,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  51%|█████     | 160/313 [02:25<02:18,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  51%|█████▏    | 161/313 [02:26<02:17,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  52%|█████▏    | 162/313 [02:27<02:15,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  52%|█████▏    | 163/313 [02:28<02:15,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  52%|█████▏    | 164/313 [02:29<02:14,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  53%|█████▎    | 165/313 [02:30<02:14,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  53%|█████▎    | 166/313 [02:31<02:14,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  53%|█████▎    | 167/313 [02:32<02:14,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  54%|█████▎    | 168/313 [02:33<02:13,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  54%|█████▍    | 169/313 [02:34<02:11,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  54%|█████▍    | 170/313 [02:34<02:10,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  55%|█████▍    | 171/313 [02:35<02:08,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  55%|█████▍    | 172/313 [02:36<02:07,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  55%|█████▌    | 173/313 [02:37<02:06,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  56%|█████▌    | 174/313 [02:38<02:05,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  56%|█████▌    | 175/313 [02:39<02:04,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  56%|█████▌    | 176/313 [02:40<02:03,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  57%|█████▋    | 177/313 [02:41<02:02,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  57%|█████▋    | 178/313 [02:42<02:02,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  57%|█████▋    | 179/313 [02:43<02:01,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  58%|█████▊    | 180/313 [02:43<02:00,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  58%|█████▊    | 181/313 [02:44<01:59,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  58%|█████▊    | 182/313 [02:45<01:59,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  58%|█████▊    | 183/313 [02:46<01:58,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  59%|█████▉    | 184/313 [02:47<01:58,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  59%|█████▉    | 185/313 [02:48<01:57,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  59%|█████▉    | 186/313 [02:49<01:55,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  60%|█████▉    | 187/313 [02:50<01:54,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  60%|██████    | 188/313 [02:51<01:53,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  60%|██████    | 189/313 [02:52<01:52,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  61%|██████    | 190/313 [02:53<01:51,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  61%|██████    | 191/313 [02:53<01:50,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  61%|██████▏   | 192/313 [02:54<01:50,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  62%|██████▏   | 193/313 [02:55<01:49,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  62%|██████▏   | 194/313 [02:56<01:47,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  62%|██████▏   | 195/313 [02:57<01:46,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  63%|██████▎   | 196/313 [02:58<01:47,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  63%|██████▎   | 197/313 [02:59<01:46,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  63%|██████▎   | 198/313 [03:00<01:45,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  64%|██████▎   | 199/313 [03:01<01:45,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  64%|██████▍   | 200/313 [03:02<01:43,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  64%|██████▍   | 201/313 [03:03<01:42,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  65%|██████▍   | 202/313 [03:04<01:40,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  65%|██████▍   | 203/313 [03:04<01:39,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  65%|██████▌   | 204/313 [03:05<01:38,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  65%|██████▌   | 205/313 [03:06<01:37,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  66%|██████▌   | 206/313 [03:07<01:36,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  66%|██████▌   | 207/313 [03:08<01:35,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  66%|██████▋   | 208/313 [03:09<01:34,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  67%|██████▋   | 209/313 [03:10<01:33,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  67%|██████▋   | 210/313 [03:11<01:33,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  67%|██████▋   | 211/313 [03:12<01:31,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  68%|██████▊   | 212/313 [03:13<01:31,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  68%|██████▊   | 213/313 [03:13<01:31,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  68%|██████▊   | 214/313 [03:14<01:30,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  69%|██████▊   | 215/313 [03:15<01:30,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  69%|██████▉   | 216/313 [03:16<01:29,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  69%|██████▉   | 217/313 [03:17<01:28,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  70%|██████▉   | 218/313 [03:18<01:26,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  70%|██████▉   | 219/313 [03:19<01:25,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  70%|███████   | 220/313 [03:20<01:24,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  71%|███████   | 221/313 [03:21<01:23,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  71%|███████   | 222/313 [03:22<01:22,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  71%|███████   | 223/313 [03:23<01:21,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  72%|███████▏  | 224/313 [03:23<01:20,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  72%|███████▏  | 225/313 [03:24<01:19,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  72%|███████▏  | 226/313 [03:25<01:18,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  73%|███████▎  | 227/313 [03:26<01:18,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  73%|███████▎  | 228/313 [03:27<01:17,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  73%|███████▎  | 229/313 [03:28<01:17,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  73%|███████▎  | 230/313 [03:29<01:16,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  74%|███████▍  | 231/313 [03:30<01:15,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  74%|███████▍  | 232/313 [03:31<01:14,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  74%|███████▍  | 233/313 [03:32<01:13,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  75%|███████▍  | 234/313 [03:33<01:12,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  75%|███████▌  | 235/313 [03:34<01:10,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  75%|███████▌  | 236/313 [03:34<01:09,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  76%|███████▌  | 237/313 [03:35<01:08,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  76%|███████▌  | 238/313 [03:36<01:07,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  76%|███████▋  | 239/313 [03:37<01:06,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  77%|███████▋  | 240/313 [03:38<01:05,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  77%|███████▋  | 241/313 [03:39<01:04,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  77%|███████▋  | 242/313 [03:40<01:04,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  78%|███████▊  | 243/313 [03:41<01:03,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  78%|███████▊  | 244/313 [03:42<01:03,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  78%|███████▊  | 245/313 [03:43<01:02,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  79%|███████▊  | 246/313 [03:44<01:02,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  79%|███████▉  | 247/313 [03:44<01:00,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  79%|███████▉  | 248/313 [03:45<00:59,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  80%|███████▉  | 249/313 [03:46<00:58,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  80%|███████▉  | 250/313 [03:47<00:57,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  80%|████████  | 251/313 [03:48<00:56,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  81%|████████  | 252/313 [03:49<00:55,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  81%|████████  | 253/313 [03:50<00:54,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  81%|████████  | 254/313 [03:51<00:53,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  81%|████████▏ | 255/313 [03:52<00:52,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  82%|████████▏ | 256/313 [03:53<00:51,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  82%|████████▏ | 257/313 [03:54<00:50,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  82%|████████▏ | 258/313 [03:54<00:50,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  83%|████████▎ | 259/313 [03:55<00:49,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  83%|████████▎ | 260/313 [03:56<00:48,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  83%|████████▎ | 261/313 [03:57<00:48,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  84%|████████▎ | 262/313 [03:58<00:47,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  84%|████████▍ | 263/313 [03:59<00:46,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  84%|████████▍ | 264/313 [04:00<00:44,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  85%|████████▍ | 265/313 [04:01<00:43,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  85%|████████▍ | 266/313 [04:02<00:42,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  85%|████████▌ | 267/313 [04:03<00:41,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  86%|████████▌ | 268/313 [04:04<00:40,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  86%|████████▌ | 269/313 [04:04<00:39,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  86%|████████▋ | 270/313 [04:05<00:38,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  87%|████████▋ | 271/313 [04:06<00:37,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  87%|████████▋ | 272/313 [04:07<00:36,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  87%|████████▋ | 273/313 [04:08<00:36,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  88%|████████▊ | 274/313 [04:09<00:35,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  88%|████████▊ | 275/313 [04:10<00:34,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  88%|████████▊ | 276/313 [04:11<00:34,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  88%|████████▊ | 277/313 [04:12<00:33,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  89%|████████▉ | 278/313 [04:13<00:32,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  89%|████████▉ | 279/313 [04:14<00:31,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  89%|████████▉ | 280/313 [04:15<00:30,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  90%|████████▉ | 281/313 [04:15<00:29,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  90%|█████████ | 282/313 [04:16<00:28,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  90%|█████████ | 283/313 [04:17<00:27,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  91%|█████████ | 284/313 [04:18<00:26,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  91%|█████████ | 285/313 [04:19<00:25,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  91%|█████████▏| 286/313 [04:20<00:24,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  92%|█████████▏| 287/313 [04:21<00:23,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  92%|█████████▏| 288/313 [04:22<00:22,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  92%|█████████▏| 289/313 [04:23<00:21,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  93%|█████████▎| 290/313 [04:24<00:20,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  93%|█████████▎| 291/313 [04:25<00:20,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  93%|█████████▎| 292/313 [04:25<00:19,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  94%|█████████▎| 293/313 [04:26<00:18,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  94%|█████████▍| 294/313 [04:27<00:17,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  94%|█████████▍| 295/313 [04:28<00:16,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  95%|█████████▍| 296/313 [04:29<00:15,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  95%|█████████▍| 297/313 [04:30<00:14,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  95%|█████████▌| 298/313 [04:31<00:13,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  96%|█████████▌| 299/313 [04:32<00:12,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  96%|█████████▌| 300/313 [04:33<00:11,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  96%|█████████▌| 301/313 [04:34<00:10,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  96%|█████████▋| 302/313 [04:35<00:09,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  97%|█████████▋| 303/313 [04:35<00:09,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  97%|█████████▋| 304/313 [04:36<00:08,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  97%|█████████▋| 305/313 [04:37<00:07,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  98%|█████████▊| 306/313 [04:38<00:06,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  98%|█████████▊| 307/313 [04:39<00:05,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  98%|█████████▊| 308/313 [04:40<00:04,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  99%|█████████▊| 309/313 [04:41<00:03,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  99%|█████████▉| 310/313 [04:42<00:02,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  99%|█████████▉| 311/313 [04:43<00:01,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples: 100%|█████████▉| 312/313 [04:44<00:00,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples: 100%|██████████| 313/313 [04:44<00:00,  1.10 Batches/s]\n",
            "Documents Processed:  69%|██████▉   | 40000/57638 [20:00<08:48, 33.35 docs/s]\n",
            "Inferencing Samples:   0%|          | 0/313 [00:00<?, ? Batches/s]\u001b[A\n",
            "Documents Processed:  69%|██████▉   | 40000/57638 [20:14<08:48, 33.35 docs/s]\n",
            "Inferencing Samples:   1%|          | 2/313 [00:01<04:46,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   1%|          | 3/313 [00:02<04:39,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   1%|▏         | 4/313 [00:03<04:35,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   2%|▏         | 5/313 [00:04<04:34,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   2%|▏         | 6/313 [00:05<04:32,  1.13 Batches/s]\u001b[A\n",
            "Inferencing Samples:   2%|▏         | 7/313 [00:06<04:32,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   3%|▎         | 8/313 [00:07<04:31,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   3%|▎         | 9/313 [00:08<04:33,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   3%|▎         | 10/313 [00:09<04:34,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   4%|▎         | 11/313 [00:09<04:35,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   4%|▍         | 12/313 [00:10<04:35,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   4%|▍         | 13/313 [00:11<04:34,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   4%|▍         | 14/313 [00:12<04:32,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   5%|▍         | 15/313 [00:13<04:30,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   5%|▌         | 16/313 [00:14<04:29,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   5%|▌         | 17/313 [00:15<04:28,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   6%|▌         | 18/313 [00:16<04:27,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   6%|▌         | 19/313 [00:17<04:26,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   6%|▋         | 20/313 [00:18<04:25,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   7%|▋         | 21/313 [00:19<04:25,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   7%|▋         | 22/313 [00:19<04:24,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   7%|▋         | 23/313 [00:20<04:24,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   8%|▊         | 24/313 [00:21<04:25,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   8%|▊         | 25/313 [00:22<04:27,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:   8%|▊         | 26/313 [00:23<04:27,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:   9%|▊         | 27/313 [00:24<04:27,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:   9%|▉         | 28/313 [00:25<04:26,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:   9%|▉         | 29/313 [00:26<04:24,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  10%|▉         | 30/313 [00:27<04:22,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  10%|▉         | 31/313 [00:28<04:20,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  10%|█         | 32/313 [00:29<04:18,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  11%|█         | 33/313 [00:30<04:17,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  11%|█         | 34/313 [00:31<04:15,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  11%|█         | 35/313 [00:31<04:14,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  12%|█▏        | 36/313 [00:32<04:13,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  12%|█▏        | 37/313 [00:33<04:11,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  12%|█▏        | 38/313 [00:34<04:10,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  12%|█▏        | 39/313 [00:35<04:09,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  13%|█▎        | 40/313 [00:36<04:11,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  13%|█▎        | 41/313 [00:37<04:11,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  13%|█▎        | 42/313 [00:38<04:11,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  14%|█▎        | 43/313 [00:39<04:11,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  14%|█▍        | 44/313 [00:40<04:11,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  14%|█▍        | 45/313 [00:41<04:08,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  15%|█▍        | 46/313 [00:42<04:06,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  15%|█▌        | 47/313 [00:43<04:04,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  15%|█▌        | 48/313 [00:43<04:02,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  16%|█▌        | 49/313 [00:44<04:01,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  16%|█▌        | 50/313 [00:45<04:00,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  16%|█▋        | 51/313 [00:46<03:58,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  17%|█▋        | 52/313 [00:47<03:57,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  17%|█▋        | 53/313 [00:48<03:56,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  17%|█▋        | 54/313 [00:49<03:55,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  18%|█▊        | 55/313 [00:50<03:54,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  18%|█▊        | 56/313 [00:51<03:54,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  18%|█▊        | 57/313 [00:52<03:54,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  19%|█▊        | 58/313 [00:53<03:56,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  19%|█▉        | 59/313 [00:54<03:55,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  19%|█▉        | 60/313 [00:54<03:53,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  19%|█▉        | 61/313 [00:55<03:50,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  20%|█▉        | 62/313 [00:56<03:48,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  20%|██        | 63/313 [00:57<03:47,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  20%|██        | 64/313 [00:58<03:45,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  21%|██        | 65/313 [00:59<03:43,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  21%|██        | 66/313 [01:00<03:43,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  21%|██▏       | 67/313 [01:01<03:41,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  22%|██▏       | 68/313 [01:02<03:40,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  22%|██▏       | 69/313 [01:03<03:39,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  22%|██▏       | 70/313 [01:03<03:39,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  23%|██▎       | 71/313 [01:04<03:37,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  23%|██▎       | 72/313 [01:05<03:38,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  23%|██▎       | 73/313 [01:06<03:39,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  24%|██▎       | 74/313 [01:07<03:39,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  24%|██▍       | 75/313 [01:08<03:39,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  24%|██▍       | 76/313 [01:09<03:36,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  25%|██▍       | 77/313 [01:10<03:33,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  25%|██▍       | 78/313 [01:11<03:31,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  25%|██▌       | 79/313 [01:12<03:30,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  26%|██▌       | 80/313 [01:13<03:29,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  26%|██▌       | 81/313 [01:13<03:28,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  26%|██▌       | 82/313 [01:14<03:27,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  27%|██▋       | 83/313 [01:15<03:25,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  27%|██▋       | 84/313 [01:16<03:24,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  27%|██▋       | 85/313 [01:17<03:23,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  27%|██▋       | 86/313 [01:18<03:22,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  28%|██▊       | 87/313 [01:19<03:20,  1.13 Batches/s]\u001b[A\n",
            "Inferencing Samples:  28%|██▊       | 88/313 [01:20<03:22,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  28%|██▊       | 89/313 [01:21<03:22,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  29%|██▉       | 90/313 [01:21<03:22,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  29%|██▉       | 91/313 [01:22<03:22,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  29%|██▉       | 92/313 [01:23<03:20,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  30%|██▉       | 93/313 [01:24<03:19,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  30%|███       | 94/313 [01:25<03:16,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  30%|███       | 95/313 [01:26<03:15,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  31%|███       | 96/313 [01:27<03:14,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  31%|███       | 97/313 [01:28<03:12,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  31%|███▏      | 98/313 [01:29<03:11,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  32%|███▏      | 99/313 [01:30<03:10,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  32%|███▏      | 100/313 [01:30<03:10,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  32%|███▏      | 101/313 [01:31<03:09,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  33%|███▎      | 102/313 [01:32<03:08,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  33%|███▎      | 103/313 [01:33<03:09,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  33%|███▎      | 104/313 [01:34<03:08,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  34%|███▎      | 105/313 [01:35<03:09,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  34%|███▍      | 106/313 [01:36<03:08,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  34%|███▍      | 107/313 [01:37<03:08,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  35%|███▍      | 108/313 [01:38<03:05,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  35%|███▍      | 109/313 [01:39<03:03,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  35%|███▌      | 110/313 [01:39<03:02,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  35%|███▌      | 111/313 [01:40<03:01,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  36%|███▌      | 112/313 [01:41<03:00,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  36%|███▌      | 113/313 [01:42<02:59,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  36%|███▋      | 114/313 [01:43<02:58,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  37%|███▋      | 115/313 [01:44<02:56,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  37%|███▋      | 116/313 [01:45<02:55,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  37%|███▋      | 117/313 [01:46<02:54,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  38%|███▊      | 118/313 [01:47<02:54,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  38%|███▊      | 119/313 [01:48<02:55,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  38%|███▊      | 120/313 [01:48<02:55,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  39%|███▊      | 121/313 [01:49<02:55,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  39%|███▉      | 122/313 [01:50<02:54,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  39%|███▉      | 123/313 [01:51<02:54,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  40%|███▉      | 124/313 [01:52<02:52,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  40%|███▉      | 125/313 [01:53<02:50,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  40%|████      | 126/313 [01:54<02:49,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  41%|████      | 127/313 [01:55<02:48,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  41%|████      | 128/313 [01:56<02:46,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  41%|████      | 129/313 [01:57<02:45,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  42%|████▏     | 130/313 [01:58<02:44,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  42%|████▏     | 131/313 [01:58<02:43,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  42%|████▏     | 132/313 [01:59<02:42,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  42%|████▏     | 133/313 [02:00<02:41,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  43%|████▎     | 134/313 [02:01<02:40,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  43%|████▎     | 135/313 [02:02<02:40,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  43%|████▎     | 136/313 [02:03<02:40,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  44%|████▍     | 137/313 [02:04<02:41,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  44%|████▍     | 138/313 [02:05<02:40,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  44%|████▍     | 139/313 [02:06<02:39,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  45%|████▍     | 140/313 [02:07<02:37,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  45%|████▌     | 141/313 [02:08<02:36,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  45%|████▌     | 142/313 [02:08<02:35,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  46%|████▌     | 143/313 [02:09<02:34,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  46%|████▌     | 144/313 [02:10<02:33,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  46%|████▋     | 145/313 [02:11<02:32,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  47%|████▋     | 146/313 [02:12<02:30,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  47%|████▋     | 147/313 [02:13<02:29,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  47%|████▋     | 148/313 [02:14<02:29,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  48%|████▊     | 149/313 [02:15<02:27,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  48%|████▊     | 150/313 [02:16<02:26,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  48%|████▊     | 151/313 [02:17<02:26,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  49%|████▊     | 152/313 [02:18<02:27,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  49%|████▉     | 153/313 [02:18<02:27,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  49%|████▉     | 154/313 [02:19<02:26,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  50%|████▉     | 155/313 [02:20<02:25,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  50%|████▉     | 156/313 [02:21<02:23,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  50%|█████     | 157/313 [02:22<02:21,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  50%|█████     | 158/313 [02:23<02:21,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  51%|█████     | 159/313 [02:24<02:19,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  51%|█████     | 160/313 [02:25<02:18,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  51%|█████▏    | 161/313 [02:26<02:17,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  52%|█████▏    | 162/313 [02:27<02:17,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  52%|█████▏    | 163/313 [02:28<02:16,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  52%|█████▏    | 164/313 [02:28<02:15,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  53%|█████▎    | 165/313 [02:29<02:14,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  53%|█████▎    | 166/313 [02:30<02:14,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  53%|█████▎    | 167/313 [02:31<02:13,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  54%|█████▎    | 168/313 [02:32<02:13,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  54%|█████▍    | 169/313 [02:33<02:12,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  54%|█████▍    | 170/313 [02:34<02:12,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  55%|█████▍    | 171/313 [02:35<02:10,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  55%|█████▍    | 172/313 [02:36<02:08,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  55%|█████▌    | 173/313 [02:37<02:07,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  56%|█████▌    | 174/313 [02:38<02:06,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  56%|█████▌    | 175/313 [02:38<02:05,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  56%|█████▌    | 176/313 [02:39<02:03,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  57%|█████▋    | 177/313 [02:40<02:02,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  57%|█████▋    | 178/313 [02:41<02:01,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  57%|█████▋    | 179/313 [02:42<02:00,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  58%|█████▊    | 180/313 [02:43<01:59,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  58%|█████▊    | 181/313 [02:44<01:58,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  58%|█████▊    | 182/313 [02:45<01:58,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  58%|█████▊    | 183/313 [02:46<01:58,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  59%|█████▉    | 184/313 [02:47<01:58,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  59%|█████▉    | 185/313 [02:48<01:57,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  59%|█████▉    | 186/313 [02:49<01:58,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  60%|█████▉    | 187/313 [02:49<01:55,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  60%|██████    | 188/313 [02:50<01:54,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  60%|██████    | 189/313 [02:51<01:52,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  61%|██████    | 190/313 [02:52<01:51,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  61%|██████    | 191/313 [02:53<01:50,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  61%|██████▏   | 192/313 [02:54<01:49,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  62%|██████▏   | 193/313 [02:55<01:48,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  62%|██████▏   | 194/313 [02:56<01:46,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  62%|██████▏   | 195/313 [02:57<01:46,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  63%|██████▎   | 196/313 [02:57<01:45,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  63%|██████▎   | 197/313 [02:58<01:44,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  63%|██████▎   | 198/313 [02:59<01:44,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  64%|██████▎   | 199/313 [03:00<01:44,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  64%|██████▍   | 200/313 [03:01<01:44,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  64%|██████▍   | 201/313 [03:02<01:43,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  65%|██████▍   | 202/313 [03:03<01:41,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  65%|██████▍   | 203/313 [03:04<01:40,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  65%|██████▌   | 204/313 [03:05<01:38,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  65%|██████▌   | 205/313 [03:06<01:37,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  66%|██████▌   | 206/313 [03:07<01:35,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  66%|██████▌   | 207/313 [03:07<01:35,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  66%|██████▋   | 208/313 [03:08<01:34,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  67%|██████▋   | 209/313 [03:09<01:33,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  67%|██████▋   | 210/313 [03:10<01:32,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  67%|██████▋   | 211/313 [03:11<01:31,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  68%|██████▊   | 212/313 [03:12<01:30,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  68%|██████▊   | 213/313 [03:13<01:30,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  68%|██████▊   | 214/313 [03:14<01:29,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  69%|██████▊   | 215/313 [03:15<01:29,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  69%|██████▉   | 216/313 [03:16<01:29,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  69%|██████▉   | 217/313 [03:17<01:28,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  70%|██████▉   | 218/313 [03:18<01:27,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  70%|██████▉   | 219/313 [03:18<01:25,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  70%|███████   | 220/313 [03:19<01:24,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  71%|███████   | 221/313 [03:20<01:23,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  71%|███████   | 222/313 [03:21<01:21,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  71%|███████   | 223/313 [03:22<01:21,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  72%|███████▏  | 224/313 [03:23<01:20,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  72%|███████▏  | 225/313 [03:24<01:19,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  72%|███████▏  | 226/313 [03:25<01:18,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  73%|███████▎  | 227/313 [03:26<01:17,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  73%|███████▎  | 228/313 [03:26<01:16,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  73%|███████▎  | 229/313 [03:27<01:15,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  73%|███████▎  | 230/313 [03:28<01:16,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  74%|███████▍  | 231/313 [03:29<01:15,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  74%|███████▍  | 232/313 [03:30<01:14,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  74%|███████▍  | 233/313 [03:31<01:13,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  75%|███████▍  | 234/313 [03:32<01:12,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  75%|███████▌  | 235/313 [03:33<01:11,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  75%|███████▌  | 236/313 [03:34<01:10,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  76%|███████▌  | 237/313 [03:35<01:09,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  76%|███████▌  | 238/313 [03:36<01:07,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  76%|███████▋  | 239/313 [03:37<01:06,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  77%|███████▋  | 240/313 [03:37<01:05,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  77%|███████▋  | 241/313 [03:38<01:04,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  77%|███████▋  | 242/313 [03:39<01:04,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  78%|███████▊  | 243/313 [03:40<01:03,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  78%|███████▊  | 244/313 [03:41<01:02,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  78%|███████▊  | 245/313 [03:42<01:01,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  79%|███████▊  | 246/313 [03:43<01:00,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  79%|███████▉  | 247/313 [03:44<01:00,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  79%|███████▉  | 248/313 [03:45<00:59,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  80%|███████▉  | 249/313 [03:46<00:58,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  80%|███████▉  | 250/313 [03:47<00:57,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  80%|████████  | 251/313 [03:47<00:56,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  81%|████████  | 252/313 [03:48<00:55,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  81%|████████  | 253/313 [03:49<00:54,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  81%|████████  | 254/313 [03:50<00:53,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  81%|████████▏ | 255/313 [03:51<00:52,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  82%|████████▏ | 256/313 [03:52<00:51,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  82%|████████▏ | 257/313 [03:53<00:50,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  82%|████████▏ | 258/313 [03:54<00:49,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  83%|████████▎ | 259/313 [03:55<00:48,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  83%|████████▎ | 260/313 [03:56<00:47,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  83%|████████▎ | 261/313 [03:56<00:46,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  84%|████████▎ | 262/313 [03:57<00:46,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  84%|████████▍ | 263/313 [03:58<00:45,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  84%|████████▍ | 264/313 [03:59<00:45,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  85%|████████▍ | 265/313 [04:00<00:44,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  85%|████████▍ | 266/313 [04:01<00:43,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  85%|████████▌ | 267/313 [04:02<00:42,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  86%|████████▌ | 268/313 [04:03<00:40,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  86%|████████▌ | 269/313 [04:04<00:39,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  86%|████████▋ | 270/313 [04:05<00:38,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  87%|████████▋ | 271/313 [04:06<00:37,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  87%|████████▋ | 272/313 [04:06<00:36,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  87%|████████▋ | 273/313 [04:07<00:36,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  88%|████████▊ | 274/313 [04:08<00:35,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  88%|████████▊ | 275/313 [04:09<00:34,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  88%|████████▊ | 276/313 [04:10<00:33,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  88%|████████▊ | 277/313 [04:11<00:32,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  89%|████████▉ | 278/313 [04:12<00:31,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  89%|████████▉ | 279/313 [04:13<00:31,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  89%|████████▉ | 280/313 [04:14<00:30,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  90%|████████▉ | 281/313 [04:15<00:29,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  90%|█████████ | 282/313 [04:16<00:28,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  90%|█████████ | 283/313 [04:16<00:27,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  91%|█████████ | 284/313 [04:17<00:26,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  91%|█████████ | 285/313 [04:18<00:25,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  91%|█████████▏| 286/313 [04:19<00:24,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  92%|█████████▏| 287/313 [04:20<00:23,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  92%|█████████▏| 288/313 [04:21<00:22,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  92%|█████████▏| 289/313 [04:22<00:21,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  93%|█████████▎| 290/313 [04:23<00:20,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  93%|█████████▎| 291/313 [04:24<00:19,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  93%|█████████▎| 292/313 [04:25<00:18,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  94%|█████████▎| 293/313 [04:25<00:18,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  94%|█████████▍| 294/313 [04:26<00:17,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  94%|█████████▍| 295/313 [04:27<00:16,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  95%|█████████▍| 296/313 [04:28<00:15,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  95%|█████████▍| 297/313 [04:29<00:14,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  95%|█████████▌| 298/313 [04:30<00:13,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  96%|█████████▌| 299/313 [04:31<00:12,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  96%|█████████▌| 300/313 [04:32<00:11,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  96%|█████████▌| 301/313 [04:33<00:10,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  96%|█████████▋| 302/313 [04:34<00:09,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  97%|█████████▋| 303/313 [04:35<00:09,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  97%|█████████▋| 304/313 [04:36<00:08,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  97%|█████████▋| 305/313 [04:36<00:07,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  98%|█████████▊| 306/313 [04:37<00:06,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  98%|█████████▊| 307/313 [04:38<00:05,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  98%|█████████▊| 308/313 [04:39<00:04,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  99%|█████████▊| 309/313 [04:40<00:03,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  99%|█████████▉| 310/313 [04:41<00:02,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  99%|█████████▉| 311/313 [04:42<00:01,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples: 100%|█████████▉| 312/313 [04:43<00:00,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples: 100%|██████████| 313/313 [04:43<00:00,  1.10 Batches/s]\n",
            "Documents Processed:  87%|████████▋ | 50000/57638 [24:59<03:48, 33.39 docs/s]\n",
            "Inferencing Samples:   0%|          | 0/239 [00:00<?, ? Batches/s]\u001b[A\n",
            "Inferencing Samples:   0%|          | 1/239 [00:01<03:59,  1.01s/ Batches]\u001b[A\n",
            "Inferencing Samples:   1%|          | 2/239 [00:01<03:45,  1.05 Batches/s]\u001b[A\n",
            "Documents Processed:  87%|████████▋ | 50000/57638 [25:10<03:48, 33.39 docs/s]\n",
            "Inferencing Samples:   2%|▏         | 4/239 [00:03<03:36,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:   2%|▏         | 5/239 [00:04<03:32,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:   3%|▎         | 6/239 [00:05<03:30,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   3%|▎         | 7/239 [00:06<03:28,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   3%|▎         | 8/239 [00:07<03:26,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   4%|▍         | 9/239 [00:08<03:25,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   4%|▍         | 10/239 [00:09<03:24,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   5%|▍         | 11/239 [00:09<03:23,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   5%|▌         | 12/239 [00:10<03:22,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   5%|▌         | 13/239 [00:11<03:22,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   6%|▌         | 14/239 [00:12<03:21,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:   6%|▋         | 15/239 [00:13<03:22,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   7%|▋         | 16/239 [00:14<03:21,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:   7%|▋         | 17/239 [00:15<03:22,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   8%|▊         | 18/239 [00:16<03:23,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:   8%|▊         | 19/239 [00:17<03:23,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:   8%|▊         | 20/239 [00:18<03:22,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:   9%|▉         | 21/239 [00:19<03:20,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:   9%|▉         | 22/239 [00:20<03:18,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  10%|▉         | 23/239 [00:20<03:17,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  10%|█         | 24/239 [00:21<03:16,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  10%|█         | 25/239 [00:22<03:15,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  11%|█         | 26/239 [00:23<03:14,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  11%|█▏        | 27/239 [00:24<03:13,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  12%|█▏        | 28/239 [00:25<03:12,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  12%|█▏        | 29/239 [00:26<03:11,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  13%|█▎        | 30/239 [00:27<03:10,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  13%|█▎        | 31/239 [00:28<03:11,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  13%|█▎        | 32/239 [00:29<03:11,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  14%|█▍        | 33/239 [00:30<03:11,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  14%|█▍        | 34/239 [00:31<03:10,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  15%|█▍        | 35/239 [00:31<03:08,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  15%|█▌        | 36/239 [00:32<03:06,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  15%|█▌        | 37/239 [00:33<03:05,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  16%|█▌        | 38/239 [00:34<03:04,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  16%|█▋        | 39/239 [00:35<03:02,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  17%|█▋        | 40/239 [00:36<03:01,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  17%|█▋        | 41/239 [00:37<03:00,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  18%|█▊        | 42/239 [00:38<02:59,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  18%|█▊        | 43/239 [00:39<02:57,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  18%|█▊        | 44/239 [00:40<02:57,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  19%|█▉        | 45/239 [00:41<02:56,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  19%|█▉        | 46/239 [00:41<02:56,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  20%|█▉        | 47/239 [00:42<02:55,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  20%|██        | 48/239 [00:43<02:56,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  21%|██        | 49/239 [00:44<02:56,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  21%|██        | 50/239 [00:45<02:56,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  21%|██▏       | 51/239 [00:46<02:54,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  22%|██▏       | 52/239 [00:47<02:52,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  22%|██▏       | 53/239 [00:48<02:50,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  23%|██▎       | 54/239 [00:49<02:49,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  23%|██▎       | 55/239 [00:50<02:46,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  23%|██▎       | 56/239 [00:51<02:45,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  24%|██▍       | 57/239 [00:52<02:44,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  24%|██▍       | 58/239 [00:52<02:42,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  25%|██▍       | 59/239 [00:53<02:41,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  25%|██▌       | 60/239 [00:54<02:41,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  26%|██▌       | 61/239 [00:55<02:40,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  26%|██▌       | 62/239 [00:56<02:40,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  26%|██▋       | 63/239 [00:57<02:40,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  27%|██▋       | 64/239 [00:58<02:40,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  27%|██▋       | 65/239 [00:59<02:41,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  28%|██▊       | 66/239 [01:00<02:39,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  28%|██▊       | 67/239 [01:01<02:38,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  28%|██▊       | 68/239 [01:02<02:36,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  29%|██▉       | 69/239 [01:03<02:34,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  29%|██▉       | 70/239 [01:03<02:32,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  30%|██▉       | 71/239 [01:04<02:31,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  30%|███       | 72/239 [01:05<02:29,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  31%|███       | 73/239 [01:06<02:28,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  31%|███       | 74/239 [01:07<02:27,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  31%|███▏      | 75/239 [01:08<02:26,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  32%|███▏      | 76/239 [01:09<02:25,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  32%|███▏      | 77/239 [01:10<02:25,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  33%|███▎      | 78/239 [01:11<02:25,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  33%|███▎      | 79/239 [01:11<02:25,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  33%|███▎      | 80/239 [01:12<02:25,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  34%|███▍      | 81/239 [01:13<02:24,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  34%|███▍      | 82/239 [01:14<02:22,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  35%|███▍      | 83/239 [01:15<02:21,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  35%|███▌      | 84/239 [01:16<02:19,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  36%|███▌      | 85/239 [01:17<02:18,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  36%|███▌      | 86/239 [01:18<02:17,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  36%|███▋      | 87/239 [01:19<02:16,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  37%|███▋      | 88/239 [01:20<02:15,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  37%|███▋      | 89/239 [01:20<02:14,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  38%|███▊      | 90/239 [01:21<02:13,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  38%|███▊      | 91/239 [01:22<02:12,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  38%|███▊      | 92/239 [01:23<02:11,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  39%|███▉      | 93/239 [01:24<02:12,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  39%|███▉      | 94/239 [01:25<02:11,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  40%|███▉      | 95/239 [01:26<02:10,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  40%|████      | 96/239 [01:27<02:10,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  41%|████      | 97/239 [01:28<02:09,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  41%|████      | 98/239 [01:29<02:07,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  41%|████▏     | 99/239 [01:30<02:06,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  42%|████▏     | 100/239 [01:30<02:05,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  42%|████▏     | 101/239 [01:31<02:04,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  43%|████▎     | 102/239 [01:32<02:03,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  43%|████▎     | 103/239 [01:33<02:02,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  44%|████▎     | 104/239 [01:34<02:01,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  44%|████▍     | 105/239 [01:35<02:00,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  44%|████▍     | 106/239 [01:36<01:59,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  45%|████▍     | 107/239 [01:37<01:58,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  45%|████▌     | 108/239 [01:38<01:57,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  46%|████▌     | 109/239 [01:39<01:57,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  46%|████▌     | 110/239 [01:40<01:57,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  46%|████▋     | 111/239 [01:40<01:57,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  47%|████▋     | 112/239 [01:41<01:57,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  47%|████▋     | 113/239 [01:42<01:55,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  48%|████▊     | 114/239 [01:43<01:54,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  48%|████▊     | 115/239 [01:44<01:52,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  49%|████▊     | 116/239 [01:45<01:51,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  49%|████▉     | 117/239 [01:46<01:50,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  49%|████▉     | 118/239 [01:47<01:49,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  50%|████▉     | 119/239 [01:48<01:48,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  50%|█████     | 120/239 [01:49<01:47,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  51%|█████     | 121/239 [01:49<01:46,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  51%|█████     | 122/239 [01:50<01:45,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  51%|█████▏    | 123/239 [01:51<01:44,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  52%|█████▏    | 124/239 [01:52<01:44,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  52%|█████▏    | 125/239 [01:53<01:43,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  53%|█████▎    | 126/239 [01:54<01:43,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  53%|█████▎    | 127/239 [01:55<01:43,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  54%|█████▎    | 128/239 [01:56<01:42,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  54%|█████▍    | 129/239 [01:57<01:40,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  54%|█████▍    | 130/239 [01:58<01:39,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  55%|█████▍    | 131/239 [01:59<01:38,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  55%|█████▌    | 132/239 [02:00<01:37,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  56%|█████▌    | 133/239 [02:00<01:36,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  56%|█████▌    | 134/239 [02:01<01:34,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  56%|█████▋    | 135/239 [02:02<01:33,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  57%|█████▋    | 136/239 [02:03<01:33,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  57%|█████▋    | 137/239 [02:04<01:32,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  58%|█████▊    | 138/239 [02:05<01:31,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  58%|█████▊    | 139/239 [02:06<01:29,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  59%|█████▊    | 140/239 [02:07<01:29,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  59%|█████▉    | 141/239 [02:08<01:29,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  59%|█████▉    | 142/239 [02:09<01:29,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  60%|█████▉    | 143/239 [02:10<01:28,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  60%|██████    | 144/239 [02:10<01:28,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  61%|██████    | 145/239 [02:11<01:26,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  61%|██████    | 146/239 [02:12<01:24,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  62%|██████▏   | 147/239 [02:13<01:23,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  62%|██████▏   | 148/239 [02:14<01:22,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  62%|██████▏   | 149/239 [02:15<01:21,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  63%|██████▎   | 150/239 [02:16<01:20,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  63%|██████▎   | 151/239 [02:17<01:19,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  64%|██████▎   | 152/239 [02:18<01:18,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  64%|██████▍   | 153/239 [02:19<01:17,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  64%|██████▍   | 154/239 [02:19<01:16,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  65%|██████▍   | 155/239 [02:20<01:15,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  65%|██████▌   | 156/239 [02:21<01:15,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  66%|██████▌   | 157/239 [02:22<01:15,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  66%|██████▌   | 158/239 [02:23<01:14,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  67%|██████▋   | 159/239 [02:24<01:13,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  67%|██████▋   | 160/239 [02:25<01:13,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  67%|██████▋   | 161/239 [02:26<01:11,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  68%|██████▊   | 162/239 [02:27<01:10,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  68%|██████▊   | 163/239 [02:28<01:09,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  69%|██████▊   | 164/239 [02:29<01:08,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  69%|██████▉   | 165/239 [02:30<01:07,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  69%|██████▉   | 166/239 [02:30<01:06,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  70%|██████▉   | 167/239 [02:31<01:05,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  70%|███████   | 168/239 [02:32<01:03,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  71%|███████   | 169/239 [02:33<01:03,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  71%|███████   | 170/239 [02:34<01:02,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  72%|███████▏  | 171/239 [02:35<01:01,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  72%|███████▏  | 172/239 [02:36<01:00,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  72%|███████▏  | 173/239 [02:37<01:00,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  73%|███████▎  | 174/239 [02:38<01:00,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  73%|███████▎  | 175/239 [02:39<00:59,  1.07 Batches/s]\u001b[A\n",
            "Inferencing Samples:  74%|███████▎  | 176/239 [02:40<00:58,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  74%|███████▍  | 177/239 [02:40<00:56,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  74%|███████▍  | 178/239 [02:41<00:55,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  75%|███████▍  | 179/239 [02:42<00:54,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  75%|███████▌  | 180/239 [02:43<00:53,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  76%|███████▌  | 181/239 [02:44<00:52,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  76%|███████▌  | 182/239 [02:45<00:51,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  77%|███████▋  | 183/239 [02:46<00:50,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  77%|███████▋  | 184/239 [02:47<00:49,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  77%|███████▋  | 185/239 [02:48<00:48,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  78%|███████▊  | 186/239 [02:49<00:47,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  78%|███████▊  | 187/239 [02:49<00:46,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  79%|███████▊  | 188/239 [02:50<00:46,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  79%|███████▉  | 189/239 [02:51<00:45,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  79%|███████▉  | 190/239 [02:52<00:45,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  80%|███████▉  | 191/239 [02:53<00:44,  1.08 Batches/s]\u001b[A\n",
            "Inferencing Samples:  80%|████████  | 192/239 [02:54<00:43,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  81%|████████  | 193/239 [02:55<00:41,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  81%|████████  | 194/239 [02:56<00:40,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  82%|████████▏ | 195/239 [02:57<00:39,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  82%|████████▏ | 196/239 [02:58<00:38,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  82%|████████▏ | 197/239 [02:59<00:37,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  83%|████████▎ | 198/239 [03:00<00:37,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  83%|████████▎ | 199/239 [03:00<00:36,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  84%|████████▎ | 200/239 [03:01<00:35,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  84%|████████▍ | 201/239 [03:02<00:34,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  85%|████████▍ | 202/239 [03:03<00:33,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  85%|████████▍ | 203/239 [03:04<00:32,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  85%|████████▌ | 204/239 [03:05<00:31,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  86%|████████▌ | 205/239 [03:06<00:31,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  86%|████████▌ | 206/239 [03:07<00:30,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  87%|████████▋ | 207/239 [03:08<00:29,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  87%|████████▋ | 208/239 [03:09<00:28,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  87%|████████▋ | 209/239 [03:10<00:27,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  88%|████████▊ | 210/239 [03:10<00:26,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  88%|████████▊ | 211/239 [03:11<00:25,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  89%|████████▊ | 212/239 [03:12<00:24,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  89%|████████▉ | 213/239 [03:13<00:23,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  90%|████████▉ | 214/239 [03:14<00:22,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  90%|████████▉ | 215/239 [03:15<00:21,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  90%|█████████ | 216/239 [03:16<00:20,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  91%|█████████ | 217/239 [03:17<00:19,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  91%|█████████ | 218/239 [03:18<00:19,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  92%|█████████▏| 219/239 [03:19<00:18,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  92%|█████████▏| 220/239 [03:20<00:17,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  92%|█████████▏| 221/239 [03:20<00:16,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  93%|█████████▎| 222/239 [03:21<00:15,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples:  93%|█████████▎| 223/239 [03:22<00:14,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  94%|█████████▎| 224/239 [03:23<00:13,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  94%|█████████▍| 225/239 [03:24<00:12,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  95%|█████████▍| 226/239 [03:25<00:11,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  95%|█████████▍| 227/239 [03:26<00:10,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  95%|█████████▌| 228/239 [03:27<00:09,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  96%|█████████▌| 229/239 [03:28<00:08,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  96%|█████████▌| 230/239 [03:29<00:08,  1.12 Batches/s]\u001b[A\n",
            "Inferencing Samples:  97%|█████████▋| 231/239 [03:29<00:07,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  97%|█████████▋| 232/239 [03:30<00:06,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  97%|█████████▋| 233/239 [03:31<00:05,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  98%|█████████▊| 234/239 [03:32<00:04,  1.11 Batches/s]\u001b[A\n",
            "Inferencing Samples:  98%|█████████▊| 235/239 [03:33<00:03,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  99%|█████████▊| 236/239 [03:34<00:02,  1.10 Batches/s]\u001b[A\n",
            "Inferencing Samples:  99%|█████████▉| 237/239 [03:35<00:01,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples: 100%|█████████▉| 238/239 [03:36<00:00,  1.09 Batches/s]\u001b[A\n",
            "Inferencing Samples: 100%|██████████| 239/239 [03:36<00:00,  1.10 Batches/s]\n",
            "Documents Processed: 60000 docs [28:46, 34.75 docs/s]\n"
          ]
        }
      ],
      "source": [
        "from haystack.nodes import EmbeddingRetriever\n",
        "\n",
        "retriever = EmbeddingRetriever(document_store = document_store,\n",
        "                               embedding_model=\"intfloat/multilingual-e5-base\")\n",
        "\n",
        "#generate embeddings for the documents\n",
        "document_store.update_embeddings(retriever)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yVmK6yXd4Vg"
      },
      "source": [
        "## Haystack Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oO3Bf8Zxb6NS"
      },
      "outputs": [],
      "source": [
        "from haystack import Pipeline\n",
        "query_pipeline = Pipeline()\n",
        "query_pipeline.add_node(component=retriever, name=\"Retriever\", inputs=[\"Query\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHSoccVmpqf-",
        "outputId": "969e7b43-831b-4fec-a2f4-74fb50954a7c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'documents': [],\n",
              " 'root_node': 'Query',\n",
              " 'params': {'Retriever': {'top_k': 5}},\n",
              " 'query': 'query: Co jest wydatkiem służbowym w podróży służbowej?',\n",
              " 'node_id': 'Retriever'}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = query_pipeline.run(query = \"query: Co jest wydatkiem służbowym w podróży służbowej?\",\n",
        "                            params={\"Retriever\": {\"top_k\": 5}})\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFUC2YLPogJe"
      },
      "source": [
        "# Calculating NDGC@5 for the dense retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBA8U-q8pfHN",
        "outputId": "01742a49-8fd9-4bd6-a2a5-21716ad0cb26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/pjn_lab6\n"
          ]
        }
      ],
      "source": [
        "path_to_gdrive=\"/content/drive/MyDrive/pjn_lab6\"\n",
        "%cd {path_to_gdrive}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkOLtoTwuJ3G",
        "outputId": "3b4b959d-7bc4-4e26-99bb-3429717b01e2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStrumieniowane dane wyjściowe obcięte do 5000 ostatnich wierszy.\u001b[0m\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.38 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.24 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.33 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.22 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.35 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.23 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.40 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.77 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.57 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.31 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.76 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.99 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.73 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.85 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.87 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.14 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.25 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.42 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.00 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.34 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.83 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.89 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.75 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.62 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.81 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.92 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.48 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.63 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.37 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.74 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.20 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.30 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.84 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.07 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.68 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.46 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.01 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.79 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.15 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.08 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.13 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.86 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.67 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.51 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.28 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.43 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.32 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.41 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.71 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.66 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.11 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.03 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.16 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.94 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.04 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.27 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.21 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.47 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.91 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.17 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.09 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.69 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.44 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.53 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.58 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.64 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.52 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.82 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.39 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.65 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.36 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.05 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.02 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.80 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.18 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.19 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.72 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.88 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.59 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.06 Batches/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NDCG@5 for Multilingual E5 retriever:  0.0006939107542906826\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from NDCG import calculate_ndcg\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "ndcg_scores = []\n",
        "for query in queries:\n",
        "  true_scores = {}\n",
        "  query_text = query[\"text\"]\n",
        "  query_id = query[\"_id\"]\n",
        "  for qrel in qrels[\"train\"]:\n",
        "    if qrel[\"query-id\"] == query_id:\n",
        "      true_scores[qrel[\"corpus-id\"]] = 1.0\n",
        "\n",
        "  retr_scores = {}\n",
        "  results = query_pipeline.run(query = query_text)\n",
        "  for i, doc in enumerate(results[\"documents\"]):\n",
        "    if i == 5:\n",
        "      break\n",
        "    retr_scores[doc.id] = doc.score\n",
        "\n",
        "  ndcg_scores.append(calculate_ndcg(true_scores, retr_scores))\n",
        "\n",
        "print(\"NDCG@5 for Multilingual E5 retriever: \", np.mean(np.array(ndcg_scores)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umA_sqw1C2Dr"
      },
      "source": [
        "### Summary\n",
        "\n",
        "NDCG@5 Elastic Search (lab2): **0.17** \\\n",
        "NDCG@5 for Multilingual E5 retriever: **0.00069**\n",
        "\n",
        "> Which of the methods: lexical match (e.g. ElasticSearch) or dense representation works better?\n",
        "\n",
        "ES...\n",
        "\n",
        "> Which of the methods is faster?\n",
        "\n",
        "Elastic Search: ~20min \\\n",
        "Multilingual E5 retriever: ~1h\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbkmie_UWVye"
      },
      "outputs": [],
      "source": [
        "!mv /content/faiss_document_store.db {path_to_gdrive}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}